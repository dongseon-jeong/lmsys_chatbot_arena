{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naF3I9rUw_r8"
      },
      "source": [
        "# 참고 DPO 트레이너 오류\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "ValueError                                Traceback (most recent call last)\n",
        "<ipython-input-53-c4c434e2b90d> in <cell line: 1>()\n",
        "----> 1 dpo_trainer = DPOTrainer(\n",
        "      2         model,\n",
        "      3         model_ref,\n",
        "      4         args=training_args,\n",
        "      5         beta=0.1,\n",
        "\n",
        "6 frames\n",
        "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py in tokenize_row(self, feature, model)\n",
        "    651             num_diff_len = abs(chosen_prompt_len_input_ids - rejected_prompt_len_input_ids)\n",
        "    652             if num_diff_tokens > 1 or num_diff_len > 1:\n",
        "--> 653                 raise ValueError(\n",
        "    654                     \"Chosen and rejected prompt_input_ids might only differ on the \"\n",
        "    655                     \"last token due to tokenizer merge ops.\"\n",
        "\n",
        "ValueError: Chosen and rejected prompt_input_ids might only differ on the last token due to tokenizer merge ops.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-mf0tfuwD57"
      },
      "outputs": [],
      "source": [
        "# train_dat['chosen'][7512]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGBAQVbiwKul"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "\n",
        "# p_text = train_dat['prompt'][7512]\n",
        "\n",
        "# c_text = train_dat['chosen'][7512]\n",
        "\n",
        "# r_text = train_dat['rejected'][7512]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i79iUjLDpue2"
      },
      "outputs": [],
      "source": [
        "#  def build_tokenized_answer(prompt, answer):\n",
        "#         \"\"\"\n",
        "#         Llama tokenizer does satisfy `enc(a + b) = enc(a) + enc(b)`.\n",
        "#         It does ensure `enc(a + b) = enc(a) + enc(a + b)[len(enc(a)):]`.\n",
        "#         Reference:\n",
        "#             https://github.com/EleutherAI/lm-evaluation-harness/pull/531#issuecomment-1595586257\n",
        "#         \"\"\"\n",
        "\n",
        "#         full_tokenized = tokenizer(prompt + answer, add_special_tokens=False)\n",
        "#         prompt_input_ids = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
        "\n",
        "#         answer_input_ids = full_tokenized[\"input_ids\"][len(prompt_input_ids) :]\n",
        "#         answer_attention_mask = full_tokenized[\"attention_mask\"][len(prompt_input_ids) :]\n",
        "\n",
        "#         # Concat tokens to form `enc(a) + enc(a + b)[len(enc(a)):]`\n",
        "#         full_concat_input_ids = np.concatenate([prompt_input_ids, answer_input_ids])\n",
        "\n",
        "#         # Prepare input tokens for token by token comparison\n",
        "#         full_input_ids = np.array(full_tokenized[\"input_ids\"])\n",
        "\n",
        "#         if len(full_input_ids) != len(full_concat_input_ids):\n",
        "#             raise ValueError(\"Prompt input ids and answer input ids should have the same length.\")\n",
        "\n",
        "#         # On some tokenizers, like Llama-2 tokenizer, there are occasions where tokens\n",
        "#         # can be merged together when tokenizing prompt+answer. This could result\n",
        "#         # on the last token from the prompt being different when tokenized on its own\n",
        "#         # vs when done as prompt+answer.\n",
        "#         response_token_ids_start_idx = len(prompt_input_ids)\n",
        "\n",
        "#         # If tokenized prompt is different than both prompt+answer, then it means the\n",
        "#         # last token has changed due to merging.\n",
        "#         if prompt_input_ids != full_tokenized[\"input_ids\"][:response_token_ids_start_idx]:\n",
        "#             response_token_ids_start_idx -= 1\n",
        "\n",
        "#         prompt_input_ids = full_tokenized[\"input_ids\"][:response_token_ids_start_idx]\n",
        "#         prompt_attention_mask = full_tokenized[\"attention_mask\"][:response_token_ids_start_idx]\n",
        "\n",
        "#         if len(prompt_input_ids) != len(prompt_attention_mask):\n",
        "#             raise ValueError(\"Prompt input ids and attention mask should have the same length.\")\n",
        "\n",
        "#         answer_input_ids = full_tokenized[\"input_ids\"][response_token_ids_start_idx:]\n",
        "#         answer_attention_mask = full_tokenized[\"attention_mask\"][response_token_ids_start_idx:]\n",
        "\n",
        "#         return dict(\n",
        "#             prompt_input_ids=prompt_input_ids,\n",
        "#             prompt_attention_mask=prompt_attention_mask,\n",
        "#             input_ids=answer_input_ids,\n",
        "#             attention_mask=answer_attention_mask,\n",
        "#         )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BokjFzeepuhW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# prompt_tokens = tokenizer(p_text, add_special_tokens=False)\n",
        "# prompt_tokens = {f\"prompt_{k}\": v for k, v in prompt_tokens.items()}\n",
        "\n",
        "# chosen_tokens = build_tokenized_answer(p_text, c_text)\n",
        "# rejected_tokens = build_tokenized_answer(p_text, r_text)\n",
        "\n",
        "# prompt_len_input_ids = len(prompt_tokens[\"prompt_input_ids\"])\n",
        "\n",
        "# chosen_prompt_len_input_ids = len(chosen_tokens[\"prompt_input_ids\"])\n",
        "# rejected_prompt_len_input_ids = len(rejected_tokens[\"prompt_input_ids\"])\n",
        "# prompt_len_input_ids = min(chosen_prompt_len_input_ids, rejected_prompt_len_input_ids)\n",
        "\n",
        "# for k, v in prompt_tokens.items():\n",
        "#     prompt_tokens[k] = v[:prompt_len_input_ids]\n",
        "\n",
        "# # Make sure prompts only have one different token at most an\n",
        "# # and length only differs by 1 at most\n",
        "# num_diff_tokens = sum(\n",
        "#     [a != b for a, b in zip(chosen_tokens[\"prompt_input_ids\"], rejected_tokens[\"prompt_input_ids\"])]\n",
        "# )\n",
        "# num_diff_len = abs(chosen_prompt_len_input_ids - rejected_prompt_len_input_ids)\n",
        "# if num_diff_tokens > 1 or num_diff_len > 1:\n",
        "#     raise ValueError(\n",
        "#         \"Chosen and rejected prompt_input_ids might only differ on the \"\n",
        "#         \"last token due to tokenizer merge ops.\"\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwJePMzh1PqJ"
      },
      "outputs": [],
      "source": [
        "# chosen_prompt_len_input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgQHf7aN1Psw"
      },
      "outputs": [],
      "source": [
        "# rejected_prompt_len_input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MACJgYTg1PvP"
      },
      "outputs": [],
      "source": [
        "# prompt_len_input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDfxVM5V1Ufk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CK9pU701Uh_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdntNstHBOu3"
      },
      "source": [
        "# 참고 kaggle log loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "98qUsbjNAuhU",
        "outputId": "5eea1ffa-e0af-49c5-aa3d-95eacb52c0e8"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'kaggle_metric_utilities'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-881a852d5803>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkaggle_metric_utilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kaggle_metric_utilities'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.api.types\n",
        "\n",
        "import kaggle_metric_utilities\n",
        "\n",
        "import sklearn.metrics\n",
        "\n",
        "from typing import Sequence, Union, Optional\n",
        "\n",
        "\n",
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, eps: Union[float, str]='auto', weights_column_name: Optional[str]=None, labels: Optional[Sequence]=None) -> float:\n",
        "    # Skip sorting and equality checks for the row_id_column since that should already be handled\n",
        "    del solution[row_id_column_name]\n",
        "    del submission[row_id_column_name]\n",
        "\n",
        "    sample_weight = None\n",
        "    if weights_column_name:\n",
        "        if weights_column_name not in solution.columns:\n",
        "            raise ValueError(f'The solution weights column {weights_column_name} is not found')\n",
        "        sample_weight = solution.pop(weights_column_name).values\n",
        "        if not pandas.api.types.is_numeric_dtype(sample_weight):\n",
        "            raise ParticipantVisibleError('The solution weights are not numeric')\n",
        "\n",
        "    if not pandas.api.types.is_numeric_dtype(submission.values):\n",
        "        bad_dtypes = {x: submission[x].dtype  for x in submission.columns if not pandas.api.types.is_numeric_dtype(submission[x])}\n",
        "        raise ParticipantVisibleError(f'Invalid submission data types found: {bad_dtypes}')\n",
        "\n",
        "    if submission.max().max() > 1 or submission.min().min() < 0:\n",
        "        raise ParticipantVisibleError('Submitted values were not valid probabilities')\n",
        "\n",
        "    solution = solution.values\n",
        "    submission = submission.values\n",
        "\n",
        "    score_result = kaggle_metric_utilities.safe_call_score(sklearn.metrics.log_loss, solution, submission, eps=eps, sample_weight=sample_weight, labels=labels)\n",
        "\n",
        "    return score_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX4P2Zh-8Y-Z"
      },
      "source": [
        "# Install Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRNC-mJorx3S",
        "outputId": "6ccd0052-e8d2-4de5-eed4-5db1dd69fabe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.9.4)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.10/dist-packages (1.20.0)\n",
            "Requirement already satisfied: auto-gptq in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.42.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.20.0)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.5)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum) (15.0.1)\n",
            "Collecting transformers[sentencepiece]<4.42.0,>=4.26.0 (from optimum)\n",
            "  Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.1.99)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.1)\n",
            "Requirement already satisfied: gekko in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.1.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.42.0,>=4.26.0->optimum) (3.20.3)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum) (10.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.1\n",
            "    Uninstalling transformers-4.42.1:\n",
            "      Successfully uninstalled transformers-4.42.1\n",
            "Successfully installed transformers-4.41.2\n"
          ]
        }
      ],
      "source": [
        "! pip install torch==2.0.1 peft accelerate trl optimum auto-gptq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5rSoYL_4hmJ"
      },
      "outputs": [],
      "source": [
        "! pip install bitsandbytes>=0.39.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m_RR0okt3ac",
        "outputId": "d10c04c9-afed-4135-c290-50a26f9ec59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.42.1-py3-none-any.whl (9.3 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "optimum 1.20.0 requires transformers[sentencepiece]<4.42.0,>=4.26.0, but you have transformers 4.42.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed transformers-4.42.1\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-ruWKlmyn22",
        "outputId": "7c1bf394-e4a7-4f1c-beda-31e25f79966f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (18.1.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8KOmitRyn76"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_heq8Mc8x0dv"
      },
      "source": [
        "# Load kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RGhCqTaudHW",
        "outputId": "9694047c-af50-4479-a4e7-ba1264a2e2a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgHLwWQGbLyR",
        "outputId": "04b9e109-13a1-41de-fdd9-aeabdb97c46f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/dataset/lmsys\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/drive/MyDrive/dataset/lmsys/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDN-cjJ_bklO",
        "outputId": "bfee3f27-d398-40f4-8412-7ec02891894d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 57477,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1238326827,\n        \"min\": 30192,\n        \"max\": 4294947231,\n        \"num_unique_values\": 57477,\n        \"samples\": [\n          2785062085,\n          48259531,\n          3622731894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_a\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"mistral-7b-instruct\",\n          \"guanaco-33b\",\n          \"gpt-4-1106-preview\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_b\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"llama2-70b-steerlm-chat\",\n          \"llama-13b\",\n          \"gpt-4-0613\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51734,\n        \"samples\": [\n          \"[\\\"Are autoregressive language models (e.g. GPT-3) currently more popular than auto-encoding language models (e.g. BERT)? If so, what are the explanations?\\\"]\",\n          \"[\\\"Write a c++ algorithm that aims to find the rightmost zero in a binary representation, flip it to a one, and flip any 1s to its right\\\"]\",\n          \"[\\\"What is J\\\\u00e9r\\\\u00f4me WAX ?\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56566,\n        \"samples\": [\n          \"[\\\"Tea is grown commercially in the Azores, an autonomous region of Portugal. The main tea-producing estates are located on the island of S\\\\u00e3o Miguel, where the only commercial tea plantations in Europe can be found. The most well-known tea estates on S\\\\u00e3o Miguel are Gorreana Tea Estate and Porto Formoso Tea Factory.\\\"]\",\n          \"[\\\"Sure! Here's an example to illustrate how function pointers work in C:\\\\n\\\\n```c\\\\n#include <stdio.h>\\\\n\\\\n\\\\/\\\\/ Function to be pointed to\\\\nint add(int a, int b) {\\\\n    return a + b;\\\\n}\\\\n\\\\n\\\\/\\\\/ Function to demonstrate function pointers\\\\nvoid functionPointerExample(int (*funcPtr)(int, int)) {\\\\n    int result = funcPtr(5, 10);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n}\\\\n\\\\nint main() {\\\\n    \\\\/\\\\/ Use the address-of operator (&) to get the address of the add function\\\\n    int (*addPtr)(int, int) = &add;\\\\n\\\\n    \\\\/\\\\/ Call the functionPointerExample function and pass the address of the add function\\\\n    functionPointerExample(addPtr);\\\\n\\\\n    \\\\/\\\\/ Call the add function directly\\\\n    int result = add(15, 20);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n\\\\n    return 0;\\\\n}\\\\n```\\\\n\\\\nIn this example, we define a function `add` that takes two integers as arguments and returns their sum.\\\\n\\\\nWe then define a function `functionPointerExample` that takes a function pointer as an argument. This function calls the pointed-to function passing it two integers, and then prints the result.\\\\n\\\\nIn the main function, we create a function pointer `addPtr` which points to the `add` function. We then call the `functionPointerExample` function passing the address of the `add` function using the `&` operator.\\\\n\\\\nFinally, we call the `add` function directly and store the result in a variable `result`.\\\\n\\\\nI hope this helps you understand how function pointers work in C! Let me know if you have any other questions.\\\",\\\"To define a function pointer within a struct, you can define a member variable of the struct as a pointer to a function with a specific return type and argument list. Here's an example:\\\\n\\\\n```c\\\\n#include <stdio.h>\\\\n\\\\n\\\\/\\\\/ Define a structure with a function pointer member\\\\ntypedef struct {\\\\n    int (*calculate)(int);\\\\n} Calculator;\\\\n\\\\n\\\\/\\\\/ Function to be pointed to\\\\nint add(int num) {\\\\n    return num + 10;\\\\n}\\\\n\\\\n\\\\/\\\\/ Function to demonstrate using a function pointer within a struct\\\\nvoid useCalculator(Calculator calculator) {\\\\n    int result = calculator.calculate(15);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n}\\\\n\\\\nint main() {\\\\n    \\\\/\\\\/ Create a Calculator struct and initialize the function pointer member\\\\n    Calculator calculator = { add };\\\\n\\\\n    \\\\/\\\\/ Call the useCalculator function and pass the calculator struct\\\\n    useCalculator(calculator);\\\\n\\\\n    return 0;\\\\n}\\\\n```\\\\n\\\\nIn this example, we define a `typedef` for our `Calculator` struct, which has a single member `calculate` that is a pointer to a function that takes an integer as an argument and returns an integer.\\\\n\\\\nWe then define a function `add` that adds 10 to the input integer and return the result.\\\\n\\\\nWe define a function `useCalculator` that takes a `Calculator` struct as an argument and invokes the `calculate` member function of the struct with an argument of 15.\\\\n\\\\nIn the `main` function, we create a `Calculator` struct and initialize its `calculate` member with the address of the `add` function. We then call the `useCalculator` function passing the `calculator` struct.\\\\n\\\\nI hope this helps you understand how to define a function pointer within a struct in C! Let me know if you have any other questions.\\\"]\",\n          \"[\\\"In the depths of a dark and mysterious cave, there lived a heavily pregnant cavewoman named Ula. Her thick, matted hair cascaded down her back, and her skin was tanned and rough from years of living in the harsh wilderness. Ula's husband, Kadan, was a skilled hunter and provided for their small tribe. But lately, even his sharpest arrows seemed to fall short, and food had become scarce.\\\\n\\\\nUla felt a deep ache in her bones and her swollen belly. It was the third trimester, and her baby was growing rapidly. She wondered if she would ever be able to give birth in the cramped, narrow cave. Ula's tribe had no midwife, and her only hope was to rely on the wisdom passed down from her own mother.\\\\n\\\\nOne day, while Kadan was out hunting, Ula went into labor. Her screams echoed through the cave, and her tribe gathered around her in a frenzy. Ula's eyes widened as she felt the intense pain of contractions. She was afraid for her baby's life and her own.\\\\n\\\\nThe tribe tried to comfort Ula, but their efforts fell short. Ula's baby was too big, and the birth seemed impossible. Hours passed, and Ula lost all strength. Her tribe watched in horror as Ula's life slipped away. Suddenly, a loud cry broke the silence. Ula's baby had been born, and he was healthy and strong.\\\\n\\\\nThe tribe rejoiced at the sight of the newborn. They named him Kade, after Ula's husband, Kadan. Kade was a symbol of hope and resilience, and his birth brought new life and energy to the tribe.\\\\n\\\\nAs Ula took her last breath, she whispered to Kade, \\\\\\\"May you grow up to be a fierce and proud caveman, just like your father.\\\\\\\" Ula's legacy lived on through her son, and her tribe honored her memory by carving her name into the walls of the cave. The story of Ula, the heavily pregnant cavewoman who defied death to give birth to Kade, became a legend that would be passed down through the generations.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56609,\n        \"samples\": [\n          \"[\\\"Unfortunately, I do not have enough context to provide specific details about \\\\\\\"mobility123\\\\\\\" in New Jersey. Mobility123 is not a term I am familiar with. To provide more useful information, it would be helpful if you could clarify what kind of service, company, or product mobility123 refers to, as well as any additional details about what you would like to know in relation to New Jersey. Please provide some more context and details so that I can try to assist. Let me know if you can share more information!\\\"]\",\n          \"[\\\"Abby, Amber, Amra, Arin, Arna, Ashy, Bari, Bett, Brix, Bryn, Brin, Brynne, Ciri, Cyrn, Ebby, Ebri, Elbr, Elmry, Embr, Raby, Reba\\\"]\",\n          \"[\\\"It's great that your child is considering how to communicate with her friends in a way that doesn't upset them. Here are some tips that may help:\\\\n\\\\n1. Listen actively: Encourage your child to listen to her friends without interrupting or judging them. This means paying attention to what they're saying, asking questions to clarify their thoughts, and acknowledging their feelings.\\\\n2. Use kind words: Remind your child to use kind and respectful language when talking to her friends. This means avoiding hurtful words or tone, and being mindful of how her words may be perceived by others.\\\\n3. Be empathetic: Encourage your child to try to see things from her friends' perspective and to understand their feelings and needs. This means putting herself in their shoes and considering how they might be feeling.\\\\n4. Avoid gossip: Remind your child that gossiping about her friends can be hurtful and damaging to their relationships. Encourage her to avoid talking about her friends behind their backs and to speak to them directly if she has concerns.\\\\n5. Be honest: Remind your child that honesty is always the best policy, even if it's difficult to hear. Encourage her to be open and truthful with her friends, but also to be gentle and considerate in how she delivers her message.\\\\n\\\\nBy following these tips, your child can learn how to communicate effectively with her friends without upsetting them.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_tie\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-20865c65-ddaa-4e83-8594-605c7c6183d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"Is it morally right to try to have a certain...</td>\n",
              "      <td>[\"The question of whether it is morally right ...</td>\n",
              "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"What is the difference between marriage lice...</td>\n",
              "      <td>[\"A marriage license is a legal document that ...</td>\n",
              "      <td>[\"A marriage license and a marriage certificat...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[\"explain function calling. how would you call...</td>\n",
              "      <td>[\"Function calling is the process of invoking ...</td>\n",
              "      <td>[\"Function calling is the process of invoking ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[\"How can I create a test set for a very rare ...</td>\n",
              "      <td>[\"Creating a test set for a very rare category...</td>\n",
              "      <td>[\"When building a classifier for a very rare c...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
              "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
              "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20865c65-ddaa-4e83-8594-605c7c6183d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-20865c65-ddaa-4e83-8594-605c7c6183d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-20865c65-ddaa-4e83-8594-605c7c6183d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14b08d86-c3ce-4362-a711-c3943b0ee080\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14b08d86-c3ce-4362-a711-c3943b0ee080')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14b08d86-c3ce-4362-a711-c3943b0ee080 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       id             model_a              model_b  \\\n",
              "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1   53567           koala-13b           gpt-4-0613   \n",
              "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [\"Is it morally right to try to have a certain...   \n",
              "1  [\"What is the difference between marriage lice...   \n",
              "2  [\"explain function calling. how would you call...   \n",
              "3  [\"How can I create a test set for a very rare ...   \n",
              "4  [\"What is the best way to travel from Tel-Aviv...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [\"The question of whether it is morally right ...   \n",
              "1  [\"A marriage license is a legal document that ...   \n",
              "2  [\"Function calling is the process of invoking ...   \n",
              "3  [\"Creating a test set for a very rare category...   \n",
              "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
              "1  [\"A marriage license and a marriage certificat...               0   \n",
              "2  [\"Function calling is the process of invoking ...               0   \n",
              "3  [\"When building a classifier for a very rare c...               1   \n",
              "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  \n",
              "0               0           0  \n",
              "1               1           0  \n",
              "2               0           1  \n",
              "3               0           0  \n",
              "4               1           0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_CpRuw26O99"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePh_KCr3sAib"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from transformers import AutoTokenizer, TrainingArguments, AutoModelForCausalLM, GPTQConfig, DataCollatorWithPadding, BitsAndBytesConfig\n",
        "from trl import DPOTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dioJqiSG1HzL"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "modelname = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g63rqsrgynMR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# test_df = train.copy()\n",
        "\n",
        "# def tokenize_prompt(prompt, chosen, rejected):\n",
        "#     prompt_tokens = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length = 4096)\n",
        "#     chosen_tokens = tokenizer(chosen, return_tensors=\"pt\", truncation=True, padding=True, max_length = 4096)\n",
        "#     rejected_tokens = tokenizer(rejected, return_tensors=\"pt\", truncation=True, padding=True, max_length = 4096)\n",
        "\n",
        "#     return prompt_tokens['input_ids'], chosen_tokens['input_ids'], rejected_tokens['input_ids']\n",
        "\n",
        "# p_list = []\n",
        "# c_list = []\n",
        "# r_list = []\n",
        "\n",
        "# for i in range(len(test_df)):\n",
        "#   prompt_tokens, chosen_tokens, rejected_tokens = tokenize_prompt(test_df[\"prompt\"].iloc[i], test_df[\"response_a\"].iloc[i], test_df[\"response_b\"].iloc[i])\n",
        "#   p_list.append(len(prompt_tokens[0]))\n",
        "#   c_list.append(len(chosen_tokens[0]))\n",
        "#   r_list.append(len(rejected_tokens[0]))\n",
        "\n",
        "# test_df['p_len'] = p_list\n",
        "# test_df['c_len'] = c_list\n",
        "# test_df['r_len'] = r_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UL4Vuef0cW0"
      },
      "outputs": [],
      "source": [
        "# test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKToe9Iaj8Mo"
      },
      "outputs": [],
      "source": [
        "# print(np.argmax(test_df['p_len']),\"\\n\",np.argmax(test_df['c_len']),\"\\n\",np.argmax(test_df['r_len']))\n",
        "# print(np.mean(test_df['p_len']),\"\\n\",np.mean(test_df['c_len']),\"\\n\",np.mean(test_df['r_len']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfghUDNRn7pK"
      },
      "source": [
        "# Preprocessing for DPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ0wkDwLboyj"
      },
      "outputs": [],
      "source": [
        "train = train[train['winner_tie'] == 0]\n",
        "train = train.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHpTA4YbrZ2R",
        "outputId": "bfee89e5-82eb-4784-9dd3-d06bd2049aae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 39716 entries, 0 to 39715\n",
            "Data columns (total 9 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   id              39716 non-null  int64 \n",
            " 1   model_a         39716 non-null  object\n",
            " 2   model_b         39716 non-null  object\n",
            " 3   prompt          39716 non-null  object\n",
            " 4   response_a      39716 non-null  object\n",
            " 5   response_b      39716 non-null  object\n",
            " 6   winner_model_a  39716 non-null  int64 \n",
            " 7   winner_model_b  39716 non-null  int64 \n",
            " 8   winner_tie      39716 non-null  int64 \n",
            "dtypes: int64(4), object(5)\n",
            "memory usage: 2.7+ MB\n"
          ]
        }
      ],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdmLyWb2ogll",
        "outputId": "4c7aefdd-f973-41e8-a881-5b670eaa7a7d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 39716,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1238175753,\n        \"min\": 30192,\n        \"max\": 4294947231,\n        \"num_unique_values\": 39716,\n        \"samples\": [\n          1969983266,\n          904435314,\n          1565590519\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_a\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"gpt4all-13b-snoozy\",\n          \"llama-13b\",\n          \"gpt-4-1106-preview\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_b\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"gemini-pro\",\n          \"llama-13b\",\n          \"gpt-4-0613\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 37017,\n        \"samples\": [\n          \"[\\\"\\\\\\\"a pig without 3.14 is 9.8\\\\\\\"\\\"]\",\n          \"[\\\"Generate a bunch of instructions for translation questions EN to ES (in the format of {\\\\\\\"prompt\\\\\\\": instruction}), they have to be very difficult\\\\n\\\"]\",\n          \"[\\\"Along with Company, Cluster, show the Mean return and volatility for each company as well.\\\\n\\\\ncentroids = k_means.cluster_centers_\\\\nfig = plt.figure(figsize=(16,10))\\\\nax = fig.add_subplot(111)\\\\nscatter = ax.scatter(X.iloc[:,0],X.iloc[:,1], c = k_means.labels_, cmap =\\\\\\\"rainbow\\\\\\\", label = X.index)\\\\nax.set_title('k-Means')\\\\nax.set_xlabel('Mean Return')\\\\nax.set_ylabel('Volatility')\\\\nplt.colorbar(scatter)\\\\n\\\\n# zip joins x and y coordinates in pairs\\\\nfor x,y,name in zip(X.iloc[:,0],X.iloc[:,1],X.index):\\\\n\\\\n    label = name\\\\n\\\\n    plt.annotate(label, # this is the text\\\\n                 (x,y), # this is the point to label\\\\n                 textcoords=\\\\\\\"offset points\\\\\\\", # how to position the text\\\\n                 xytext=(0,10), # distance from text to points (x,y)\\\\n                 ha='center') # horizontal alignment can be left, right or center\\\\n    \\\\nplt.plot(centroids[:,0],centroids[:,1],'sg',markersize=11)\\\\n\\\\n\\\\ncluster_label = pd.concat([pd.DataFrame(X.index), pd.DataFrame(k_means.labels_)],axis = 1)\\\\ncluster_label.columns =['Company','Cluster']\\\\ncluster_label.sort_values(by=['Cluster'])\\\\n\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39300,\n        \"samples\": [\n          \"[\\\"The debate on reducing emissions domestically versus abroad is a complex and multi-faceted issue. It mainly revolves around the question of whether it is more effective to focus on reducing greenhouse gas emissions within a country's borders or to address emissions from other countries as well. There are several arguments on both sides of the debate.\\\\n\\\\nDomestic Emissions Reduction: Proponents of focusing on domestic emissions argue that a country should first address its own emissions before attempting to influence emissions in other countries. They believe that it is more effective to take action within their own borders, where they have control over policies and infrastructure. By reducing domestic emissions, they can set an example for other countries to follow and contribute to global efforts to combat climate change.\\\\n\\\\nInternational Emissions Reduction: Advocates for addressing emissions from other countries as well argue that global action is necessary to address the issue of climate change effectively. They believe that emissions reductions should be a joint effort among all nations, as the problem is global in nature. A focus on reducing emissions worldwide can lead to more significant reductions in greenhouse gas emissions and create a more equitable distribution of the burden of emissions reductions.\\\\n\\\\nThe discourse on this topic often considers factors such as fairness, efficiency, and global cooperation. Proponents of domestic emissions reduction argue that it is only fair for a country to address its own emissions before attempting to influence others, as nations have varying levels of historical responsibility for climate change and economic capabilities to address the issue. In contrast, those who prioritize international emissions reduction argue that it is more efficient to address the issue globally, as emissions from other countries can still have an impact on a country's domestic environment and climate.\\\\n\\\\nIn conclusion, the debate on reducing emissions domestically versus abroad is a complex issue that involves various perspectives and considerations. It ultimately requires a balance between national action and international cooperation to effectively address climate change.\\\",\\\"Reducing emissions abroad: Pros and Cons\\\\n\\\\nPros:\\\\n1. Global impact: Focusing on reducing emissions abroad can have a significant global impact, as it addresses the issue in its entirety rather than just within a single country's borders. This approach can lead to more substantial reductions in greenhouse gas emissions, which is crucial for combating climate change.\\\\n2. Equitable distribution of efforts: Addressing emissions reductions globally can create a more equitable distribution of the burden, as countries with higher historical emissions or greater economic capabilities may be able to contribute more to the effort.\\\\n3. Encouraging international cooperation: A focus on reducing emissions abroad can promote international cooperation and collaboration, as countries work together to address a common global issue. This can lead to the development of more effective policies and technologies to reduce emissions.\\\\n4. Influencing other countries: By taking actions to reduce emissions abroad, a country can set an example for other nations and encourage them to follow suit. This can help to create a global culture of environmental responsibility and encourage countries to take more significant steps to address climate change.\\\\n\\\\nCons:\\\\n1. Limited control: A country may have limited control over emissions reduction efforts in other countries, which could make it challenging to ensure that the desired outcomes are achieved.\\\\n2. Economic challenges: Implementing policies and technologies to reduce emissions abroad may come with economic challenges, such as increased costs or reduced competitiveness. This could be particularly challenging for developing countries with limited resources.\\\\n3. Political barriers: Cultural, political, and institutional differences between countries can create barriers to cooperation and make it difficult to implement effective emissions reduction policies and strategies.\\\\n4. Potential for blame and finger-pointing: Focusing on reducing emissions abroad may lead to accusations of \\\\\\\"blame-shifting,\\\\\\\" where countries try to deflect responsibility for their own emissions onto others. This can create tension between nations and hinder global cooperation on climate change.\\\\n\\\\nIn summary, reducing emissions abroad has its advantages, such as promoting global impact, equitable distribution of efforts, and international cooperation. However, it also comes with challenges, such as limited control, economic challenges, political barriers, and potential for blame-shifting. Balancing these factors is essential for effective climate change mitigation efforts.\\\"]\",\n          \"[\\\"I'm sorry, but as an artificial intelligence language model, I don't have the capability to physically sell you a bagel. However, I can suggest some ways for you to acquire a bagel:\\\\n\\\\n1. Visit your local grocery store or bakery and purchase a bagel from the bread or bakery section.\\\\n2. Order bagels for delivery or pick-up from a local restaurant or caf\\\\u00e9 that serves bagels.\\\\n3. Make your own bagels at home using a bagel recipe and a bagel maker or mold.\\\\n\\\\nI hope this information helps!\\\"]\",\n          \"[\\\"In this scenario, we are dealing with a sequence of independent events, each determined by the roll of two six-sided dice. Let's analyze the probability of each player winning based on the rules provided.\\\\n\\\\nFor Alice to win, she needs to roll a seven twice in a row. The probability of rolling a seven on a single roll of two dice is the highest among all possible sums, as there are six combinations that result in a sum of seven (1+6, 2+5, 3+4, 4+3, 5+2, 6+1). Since there are 36 possible outcomes when two dice are rolled (6 x 6), the probability of rolling a seven is 6\\\\/36 or 1\\\\/6.\\\\n\\\\nFor Bob to win, he needs to roll an eight followed by a seven. The probability of rolling an eight is lower than that of a seven, as there are only five combinations that result in an eight (2+6, 3+5, 4+4, 5+3, 6+2). Therefore, the probability of rolling an eight is 5\\\\/36. To win, Bob must roll an eight (5\\\\/36), followed by a seven (1\\\\/6); thus, the probability of this happening in two consecutive rolls is (5\\\\/36) * (1\\\\/6) = 5\\\\/216.\\\\n\\\\nNow let's compare the probabilities for two consecutive turns:\\\\n\\\\n- For Alice to win, she needs to roll a seven and then another seven. The probability of this happening is (1\\\\/6) * (1\\\\/6) = 1\\\\/36.\\\\n- For Bob to win, he needs to roll an eight and then a seven. The probability of this happening is (5\\\\/36) * (1\\\\/6) = 5\\\\/216.\\\\n\\\\nWhen comparing these, we see that Alice has a higher probability of winning on any given pair of consecutive rolls.\\\\n\\\\nHowever, it is important to note that the actual game does not end after two rolls. Alice and Bob will keep rolling until one of them wins. The game is essentially a series of independent pairs of rolls, and the first person to satisfy their winning condition will end the game. This can affect the overall probability of who will win the game due to the possibility of multiple sequences of rolls occurring before a winner is determined.\\\\n\\\\nGiven the probabilities for Alice and Bob to win on any given pair of rolls, it's clear that Alice has a higher chance of winning on each pair of rolls. However, the expected number of pairs of rolls before a winner is determined is not straightforward to calculate due to the resetting nature of the game after each pair of rolls.\\\\n\\\\nAt this point, it is reasonable to conclude that Alice has a higher probability of winning any given sequence of two rolls, but without considering the possibility of multiple sequences before a win, we can't definitively say who is more likely to win the game overall. We would need to perform a more complex analysis or run a simulation to determine this.\\\\n\\\\nCONTINUE TO ITERATION 1\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39316,\n        \"samples\": [\n          \"[\\\"The result of multiplying 345 by 679 is 237,775.\\\"]\",\n          \"[\\\"42\\\"]\",\n          \"[\\\"The Stanley Cup is a prestigious award given to the champion of the National Hockey League (NHL) every year. It was first awarded in 1892, and is considered one of the most prestigious awards in professional sports. The Cup is made of sterling silver and is shaped like a bowl with a raised lip that fits around a hockey puck. The Cup is presented to the winner by the NHL president and is engraved with the winner's name and the year of their victory. The Cup has been handed out annually since 1892, except during World War II, when it was not awarded. The current champion of the Stanley Cup is the Pittsburgh Penguins, who won the Cup in 2018.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_tie\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chosen\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39327,\n        \"samples\": [\n          \"[\\\"Sure! Here is a possible implementation of the function you described in Python:\\\\n```\\\\ndef find_words(tiles, words):\\\\n    # Create a set of all the letters in the tiles string\\\\n    letters = set(tiles)\\\\n    \\\\n    # iterate over all the words in the words list\\\\n    for word in words:\\\\n        # Initialize an empty set to store the letters of the word\\\\n        word_letters = set()\\\\n        \\\\n        # iterate over the letters of the word\\\\n        for letter in word:\\\\n            # if the letter is in the set of letters from the tiles string,\\\\n            # add it to the set of letters for the word\\\\n            if letter in letters:\\\\n                word_letters.add(letter)\\\\n        \\\\n        # if the set of letters for the word is not empty, return it\\\\n        if word_letters:\\\\n            yield word\\\\n```\\\\nThis function takes two arguments: `tiles`, which is a string containing the letters to be rearranged, and `words`, which is a list of strings containing the words to be found.\\\\n\\\\nThe function first creates a set of all the letters in the `tiles` string, using the `set` constructor.\\\\n\\\\nThen, it iterates over all the words in the `words` list, and for each word, it initializes an empty set to store the letters of the word. It then iterates over the letters of the word, and for each letter, it checks if the letter is in the set of letters from the `tiles` string. If it is, it adds the letter to the set of letters for the word.\\\\n\\\\nFinally, the function iterates over the words in the `words` list, and for each word, it checks if the set of letters for the word is not empty. If it is, it yields the word.\\\\n\\\\nHere is an example of how you can use this function:\\\\n```\\\\ntiles = \\\\\\\"abcdefg\\\\\\\"\\\\nwords = [\\\\\\\"cat\\\\\\\", \\\\\\\"bat\\\\\\\", \\\\\\\"act\\\\\\\", \\\\\\\"tab\\\\\\\"]\\\\n\\\\n# print all the words that can be made by rearranging the letters in \\\\\\\"abcdefg\\\\\\\"\\\\nprint(list(find_words(tiles, words)))\\\\n# output: [\\\\\\\"cat\\\\\\\", \\\\\\\"bat\\\\\\\", \\\\\\\"act\\\\\\\", \\\\\\\"tab\\\\\\\"]\\\\n```\\\\nI hope this helps! Let me know if you have any questions or if you'd like to see any modifications to the function.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rejected\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39239,\n        \"samples\": [\n          \"[\\\"Absolutely, the acoustic properties of speech can communicate a wide range of feelings and emotions. These properties include pitch, intensity (loudness), tempo (speed), and timbre (tone quality). Here's a brief overview of how these properties can convey different emotions:\\\\n\\\\n1. Pitch: Pitch refers to how high or low a sound is. In spoken language, a higher pitch often conveys excitement, anxiety, or fear, while a lower pitch can indicate boredom, relaxation, or confidence. For example, when someone is excited or alarmed, their voice may rise in pitch. Conversely, when someone is bored or uninterested, their voice may drop in pitch.\\\\n2. Intensity (Loudness): Intensity refers to how soft or loud a sound is. An increase in intensity can signal anger, frustration, or surprise. For example, when someone shouts, it often indicates they are feeling strong emotions. Decreased intensity, on the other hand, can suggest sadness, tiredness, or shame.\\\\n3. Tempo (Speed): Tempo refers to the rate at which sounds are produced. A faster tempo can indicate urgency, excitement, or nervousness. For example, when someone is excited, they might speak quickly. Conversely, a slower tempo can suggest boredom, hesitation, or thoughtfulness.\\\\n4. Timbre (Tone Quality): Timbre refers to the quality of a sound, often described as its warmth, brightness, or harshness. A harsher, more abrupt timbre may indicate anger or frustration, while a softer, more gentle timbre can signal sadness or empathy.\\\\n\\\\nIt's important to note that these relationships between acoustic properties and emotions are not absolute and can vary depending on cultural and individual differences. However, they provide a general guideline for understanding the correlation between certain feelings and acoustic features in spoken language.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7071d189-ea5d-44fa-bb6f-d9172cc1725c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "      <th>chosen</th>\n",
              "      <th>rejected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"Is it morally right to try to have a certain...</td>\n",
              "      <td>[\"The question of whether it is morally right ...</td>\n",
              "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[\"The question of whether it is morally right ...</td>\n",
              "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"What is the difference between marriage lice...</td>\n",
              "      <td>[\"A marriage license is a legal document that ...</td>\n",
              "      <td>[\"A marriage license and a marriage certificat...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[\"A marriage license and a marriage certificat...</td>\n",
              "      <td>[\"A marriage license is a legal document that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[\"How can I create a test set for a very rare ...</td>\n",
              "      <td>[\"Creating a test set for a very rare category...</td>\n",
              "      <td>[\"When building a classifier for a very rare c...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[\"Creating a test set for a very rare category...</td>\n",
              "      <td>[\"When building a classifier for a very rare c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
              "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
              "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
              "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>292873</td>\n",
              "      <td>vicuna-13b</td>\n",
              "      <td>gpt-4-0314</td>\n",
              "      <td>[\"Construct a rap battle, in the style of Epic...</td>\n",
              "      <td>[\"[Zeus]\\nYo, it's the king of the gods on the...</td>\n",
              "      <td>[\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...</td>\n",
              "      <td>[\"[Zeus]\\nYo, it's the king of the gods on the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7071d189-ea5d-44fa-bb6f-d9172cc1725c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7071d189-ea5d-44fa-bb6f-d9172cc1725c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7071d189-ea5d-44fa-bb6f-d9172cc1725c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-43d3d2ce-a547-40bd-8182-c028572f7f95\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43d3d2ce-a547-40bd-8182-c028572f7f95')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-43d3d2ce-a547-40bd-8182-c028572f7f95 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       id             model_a              model_b  \\\n",
              "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1   53567           koala-13b           gpt-4-0613   \n",
              "2   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "3  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "4  292873          vicuna-13b           gpt-4-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [\"Is it morally right to try to have a certain...   \n",
              "1  [\"What is the difference between marriage lice...   \n",
              "2  [\"How can I create a test set for a very rare ...   \n",
              "3  [\"What is the best way to travel from Tel-Aviv...   \n",
              "4  [\"Construct a rap battle, in the style of Epic...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [\"The question of whether it is morally right ...   \n",
              "1  [\"A marriage license is a legal document that ...   \n",
              "2  [\"Creating a test set for a very rare category...   \n",
              "3  [\"The best way to travel from Tel Aviv to Jeru...   \n",
              "4  [\"[Zeus]\\nYo, it's the king of the gods on the...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
              "1  [\"A marriage license and a marriage certificat...               0   \n",
              "2  [\"When building a classifier for a very rare c...               1   \n",
              "3  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
              "4  [\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  \\\n",
              "0               0           0   \n",
              "1               1           0   \n",
              "2               0           0   \n",
              "3               1           0   \n",
              "4               1           0   \n",
              "\n",
              "                                              chosen  \\\n",
              "0  [\"The question of whether it is morally right ...   \n",
              "1  [\"A marriage license and a marriage certificat...   \n",
              "2  [\"Creating a test set for a very rare category...   \n",
              "3  [\"The best way to travel from Tel-Aviv to Jeru...   \n",
              "4  [\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...   \n",
              "\n",
              "                                            rejected  \n",
              "0  [\"As an AI, I don't have personal beliefs or o...  \n",
              "1  [\"A marriage license is a legal document that ...  \n",
              "2  [\"When building a classifier for a very rare c...  \n",
              "3  [\"The best way to travel from Tel Aviv to Jeru...  \n",
              "4  [\"[Zeus]\\nYo, it's the king of the gods on the...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chosen = []\n",
        "rejected = []\n",
        "\n",
        "\n",
        "for i in range(len(train)):\n",
        "\n",
        "  if train['winner_model_a'].iloc[i] == 1:\n",
        "    chosen.append(train['response_a'].iloc[i])\n",
        "    rejected.append(train['response_b'].iloc[i])\n",
        "  else :\n",
        "    chosen.append(train['response_b'].iloc[i])\n",
        "    rejected.append(train['response_a'].iloc[i])\n",
        "\n",
        "\n",
        "train['chosen'] = chosen\n",
        "train['rejected'] = rejected\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l6P7BmeohsL",
        "outputId": "5e1c63f1-66ed-4a64-ed46-96f45c20266c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"new_train\",\n  \"rows\": 39716,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 37017,\n        \"samples\": [\n          \"[\\\"\\\\\\\"a pig without 3.14 is 9.8\\\\\\\"\\\"]\",\n          \"[\\\"Generate a bunch of instructions for translation questions EN to ES (in the format of {\\\\\\\"prompt\\\\\\\": instruction}), they have to be very difficult\\\\n\\\"]\",\n          \"[\\\"Along with Company, Cluster, show the Mean return and volatility for each company as well.\\\\n\\\\ncentroids = k_means.cluster_centers_\\\\nfig = plt.figure(figsize=(16,10))\\\\nax = fig.add_subplot(111)\\\\nscatter = ax.scatter(X.iloc[:,0],X.iloc[:,1], c = k_means.labels_, cmap =\\\\\\\"rainbow\\\\\\\", label = X.index)\\\\nax.set_title('k-Means')\\\\nax.set_xlabel('Mean Return')\\\\nax.set_ylabel('Volatility')\\\\nplt.colorbar(scatter)\\\\n\\\\n# zip joins x and y coordinates in pairs\\\\nfor x,y,name in zip(X.iloc[:,0],X.iloc[:,1],X.index):\\\\n\\\\n    label = name\\\\n\\\\n    plt.annotate(label, # this is the text\\\\n                 (x,y), # this is the point to label\\\\n                 textcoords=\\\\\\\"offset points\\\\\\\", # how to position the text\\\\n                 xytext=(0,10), # distance from text to points (x,y)\\\\n                 ha='center') # horizontal alignment can be left, right or center\\\\n    \\\\nplt.plot(centroids[:,0],centroids[:,1],'sg',markersize=11)\\\\n\\\\n\\\\ncluster_label = pd.concat([pd.DataFrame(X.index), pd.DataFrame(k_means.labels_)],axis = 1)\\\\ncluster_label.columns =['Company','Cluster']\\\\ncluster_label.sort_values(by=['Cluster'])\\\\n\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chosen\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39327,\n        \"samples\": [\n          \"[\\\"Sure! Here is a possible implementation of the function you described in Python:\\\\n```\\\\ndef find_words(tiles, words):\\\\n    # Create a set of all the letters in the tiles string\\\\n    letters = set(tiles)\\\\n    \\\\n    # iterate over all the words in the words list\\\\n    for word in words:\\\\n        # Initialize an empty set to store the letters of the word\\\\n        word_letters = set()\\\\n        \\\\n        # iterate over the letters of the word\\\\n        for letter in word:\\\\n            # if the letter is in the set of letters from the tiles string,\\\\n            # add it to the set of letters for the word\\\\n            if letter in letters:\\\\n                word_letters.add(letter)\\\\n        \\\\n        # if the set of letters for the word is not empty, return it\\\\n        if word_letters:\\\\n            yield word\\\\n```\\\\nThis function takes two arguments: `tiles`, which is a string containing the letters to be rearranged, and `words`, which is a list of strings containing the words to be found.\\\\n\\\\nThe function first creates a set of all the letters in the `tiles` string, using the `set` constructor.\\\\n\\\\nThen, it iterates over all the words in the `words` list, and for each word, it initializes an empty set to store the letters of the word. It then iterates over the letters of the word, and for each letter, it checks if the letter is in the set of letters from the `tiles` string. If it is, it adds the letter to the set of letters for the word.\\\\n\\\\nFinally, the function iterates over the words in the `words` list, and for each word, it checks if the set of letters for the word is not empty. If it is, it yields the word.\\\\n\\\\nHere is an example of how you can use this function:\\\\n```\\\\ntiles = \\\\\\\"abcdefg\\\\\\\"\\\\nwords = [\\\\\\\"cat\\\\\\\", \\\\\\\"bat\\\\\\\", \\\\\\\"act\\\\\\\", \\\\\\\"tab\\\\\\\"]\\\\n\\\\n# print all the words that can be made by rearranging the letters in \\\\\\\"abcdefg\\\\\\\"\\\\nprint(list(find_words(tiles, words)))\\\\n# output: [\\\\\\\"cat\\\\\\\", \\\\\\\"bat\\\\\\\", \\\\\\\"act\\\\\\\", \\\\\\\"tab\\\\\\\"]\\\\n```\\\\nI hope this helps! Let me know if you have any questions or if you'd like to see any modifications to the function.\\\"]\",\n          \"[\\\"The MeSH terms for the given text \\\\\\\"asthma\\\\\\\", \\\\\\\"children\\\\\\\", \\\\\\\"South America\\\\\\\", and \\\\\\\"Asia\\\\\\\" can be classified as follows:\\\\n\\\\n1. Asthma - a chronic respiratory condition characterized by inflammation and narrowing of the airways, causing difficulty in breathing.\\\\n2. Child - a person between the ages of 6 and 12.\\\\n3. South America - a continent located in the Western Hemisphere, comprising countries such as Brazil, Argentina, and Peru.\\\\n4. Asia - the largest and most populous continent, including countries such as China, India, and Japan.\\\\n\\\\nThese terms can be used to categorize the article under the relevant MeSH headings for further research and analysis.\\\"]\",\n          \"[\\\"As the festive cheer envelops Cashel Library, Aoibheann and Denis graced us with their presence, officially kicking off the holiday season by illuminating our Christmas Tree. December is a time for togetherness, and we invite you to join us in the festivities. Your children can engage in a variety of Christmas-themed activities, from coloring delightful holiday pictures to solving the Christmas word search. Our reading corner beckons, offering a cozy space to immerse into the magic of a good story. The magic table is also set with a selection of festive games, providing hours of entertainment. We are eager to share the joy of the Christmas season with all our young readers, counting down the days to the holiday with a host of exciting events and activities.\\\",\\\"Immerse into the Holiday Spirit: A Festive Afternoon at the Library\\\\n\\\\nThe air was filled with the warmth of the season as Cashel Library transformed into a winter wonderland, adorned with shimmering Christmas lights that danced along the walls, casting a glow that reflected the joy of the season. The centerpiece, a beautifully adorned Christmas tree, stood proudly, its branches laden with ornaments that twinkled with every flicker of the lights.\\\\n\\\\nA harmonious blend of carols filled the air as a group of carol singers, their voices as bright as the decorations themselves, serenaded the crowd with classic Christmas melodies that echoed off the library's high ceilings. The magic table, a center of attention, beckoned the young and young at heart with its array of festive games and activities, each designed to spark imagination and foster a love for literature.\\\\n\\\\nAs the carolers took a well-deserved break, the children's eyes lit up with wonder as they approached the table, eager to engage in the holiday fun. A word search challenged their skills, hidden within the letters were the names of beloved Christmas characters and traditional treats. Coloring sheets offered a kaleidoscope of Christmas images, from Santa Claus to twinkling stars, providing a creative outlet for young imaginations.\\\\n\\\\nA special reading corner had been set up, a cozy nook with plush pillows and a reading lamp that made it perfect for snuggling up with a Christmas storybook. The scent of freshly baked mince pies wafted through the air, enticing everyone to the refreshment table where the delectable treats, served alongside hot cocoa, provided a sweet respite from the activities.\\\\n\\\\nThe event was a symphony of sights, sounds, and flavors, all coming together to create a magical experience that would be remembered long after the last carol had been sung and the lights had been dimmed. It was a celebration of community, family, and the joy of reading, all wrapped up in the festive spirit of Christmas.\\\",\\\"In the heart of Cashel, the library brimmed with Christmas cheer as twinkling lights cast a festive glow. Children's eyes sparkled with wonder at the magic table's games, while carol singers filled the air with holiday melodies. Mince pies and hot cocoa were a hit at the refreshment table. It was a merry Yuletide celebration, combining the joy of reading with the spirit of Christmas.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rejected\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39239,\n        \"samples\": [\n          \"[\\\"Absolutely, the acoustic properties of speech can communicate a wide range of feelings and emotions. These properties include pitch, intensity (loudness), tempo (speed), and timbre (tone quality). Here's a brief overview of how these properties can convey different emotions:\\\\n\\\\n1. Pitch: Pitch refers to how high or low a sound is. In spoken language, a higher pitch often conveys excitement, anxiety, or fear, while a lower pitch can indicate boredom, relaxation, or confidence. For example, when someone is excited or alarmed, their voice may rise in pitch. Conversely, when someone is bored or uninterested, their voice may drop in pitch.\\\\n2. Intensity (Loudness): Intensity refers to how soft or loud a sound is. An increase in intensity can signal anger, frustration, or surprise. For example, when someone shouts, it often indicates they are feeling strong emotions. Decreased intensity, on the other hand, can suggest sadness, tiredness, or shame.\\\\n3. Tempo (Speed): Tempo refers to the rate at which sounds are produced. A faster tempo can indicate urgency, excitement, or nervousness. For example, when someone is excited, they might speak quickly. Conversely, a slower tempo can suggest boredom, hesitation, or thoughtfulness.\\\\n4. Timbre (Tone Quality): Timbre refers to the quality of a sound, often described as its warmth, brightness, or harshness. A harsher, more abrupt timbre may indicate anger or frustration, while a softer, more gentle timbre can signal sadness or empathy.\\\\n\\\\nIt's important to note that these relationships between acoustic properties and emotions are not absolute and can vary depending on cultural and individual differences. However, they provide a general guideline for understanding the correlation between certain feelings and acoustic features in spoken language.\\\"]\",\n          \"[\\\"The mechanism of power refers to the way in which energy is transferred from one location to another. In the case of humans, the mechanism of power is through the use of physical objects that have the ability to store and transfer energy.\\\\n\\\\nOne of the most common forms of energy stored in humans is through muscle mass. Muscles contain mass and when they are used to move a heavy object, they can transfer energy from the object to the individual. This transfer of energy is what gives humans their strength and can be seen in the legs of a deadlift, which have a dead lift bar that connects to the ground.\\\\n\\\\nAnother common form of energy stored in humans is through the use of technology. Computers and smartphones have the ability to store and transfer energy, which allows humans to use and harness the power of technology for their convenience and efficiency.\\\\n\\\\nIn addition to muscles and technology, humans also store energy in their nervous systems as well. The nervous system can be thought of as a system of interconnected nerve cells that control and coordinate the body's functions. When we are not moving, the nervous system is in a resting state and can store energy for use when we are moving.\\\\n\\\\nLastly, people often store energy in their bodies through the practice of mindfulness and meditation. Mindfulness involves focusing on the present moment and letting go of distractions. This allows the body to release energy and become more efficient at storing and using energy.\\\\n\\\\nOverall, the mechanism of power in humans is that energy is stored in the body and can be used when needed. However, it is important to note that this energy is not always available, and people are often prone to using energy in a harmful or inefficient way.\\\"]\",\n          \"[\\\"As a responsible and ethical assistant, I must inform you that I cannot provide examples of sentences that would intentionally promote or facilitate unethical or illegal activities, including front-running. Front-running is a serious violation of securities regulations and can result in severe legal and financial consequences.\\\\n\\\\nInstead, I suggest focusing on ethical and legal ways to communicate with traders and investors. Here are five examples of sentences that could be used in a trader's chat communication to ensure a safe and secure transaction:\\\\n\\\\n1. \\\\\\\"Thank you for bringing this opportunity to my attention. I appreciate your due diligence in researching this investment opportunity.\\\\\\\"\\\\n2. \\\\\\\"I appreciate your patience as I review the details of this trade. I will ensure that all necessary steps are taken to facilitate a secure and efficient transaction.\\\\\\\"\\\\n3. \\\\\\\"I understand your concerns about market volatility. I will keep you updated on any developments that may impact your investment decision.\\\\\\\"\\\\n4. \\\\\\\"I apologize, but I cannot provide you with unsolicited investment advice. It is important to always conduct thorough research and due diligence before making any investment decisions.\\\\\\\"\\\\n5. \\\\\\\"I appreciate your interest in this investment opportunity. However, I must inform you that it is not suitable for your investment goals or risk tolerance. Please consult with a financial advisor to determine the best course of action for your individual circumstances.\\\\\\\"\\\\n\\\\nRemember, it is crucial to prioritize ethical and legal communication in any financial transaction to avoid any potential legal or financial consequences.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "new_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5202a177-cf7e-498b-9fed-022fe8013154\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>chosen</th>\n",
              "      <th>rejected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[\"Is it morally right to try to have a certain...</td>\n",
              "      <td>[\"The question of whether it is morally right ...</td>\n",
              "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[\"What is the difference between marriage lice...</td>\n",
              "      <td>[\"A marriage license and a marriage certificat...</td>\n",
              "      <td>[\"A marriage license is a legal document that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[\"How can I create a test set for a very rare ...</td>\n",
              "      <td>[\"Creating a test set for a very rare category...</td>\n",
              "      <td>[\"When building a classifier for a very rare c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
              "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
              "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[\"Construct a rap battle, in the style of Epic...</td>\n",
              "      <td>[\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...</td>\n",
              "      <td>[\"[Zeus]\\nYo, it's the king of the gods on the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39711</th>\n",
              "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
              "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
              "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39712</th>\n",
              "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
              "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
              "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39713</th>\n",
              "      <td>[\"is it unethical to work on building weapons?...</td>\n",
              "      <td>[\"Working on weapons technology raises some et...</td>\n",
              "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39714</th>\n",
              "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
              "      <td>[\"As an AI language model, I do not promote or...</td>\n",
              "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39715</th>\n",
              "      <td>[\"three kids eat three apples in three days, h...</td>\n",
              "      <td>[\"27 apples\"]</td>\n",
              "      <td>[\"If three kids eat three apples in three days...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39716 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5202a177-cf7e-498b-9fed-022fe8013154')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5202a177-cf7e-498b-9fed-022fe8013154 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5202a177-cf7e-498b-9fed-022fe8013154');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b45380e1-c851-4367-8b57-5100a3b2c87b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b45380e1-c851-4367-8b57-5100a3b2c87b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b45380e1-c851-4367-8b57-5100a3b2c87b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_008d2c5f-76a1-4943-a8e7-4da86c98c537\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('new_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_008d2c5f-76a1-4943-a8e7-4da86c98c537 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('new_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                  prompt  \\\n",
              "0      [\"Is it morally right to try to have a certain...   \n",
              "1      [\"What is the difference between marriage lice...   \n",
              "2      [\"How can I create a test set for a very rare ...   \n",
              "3      [\"What is the best way to travel from Tel-Aviv...   \n",
              "4      [\"Construct a rap battle, in the style of Epic...   \n",
              "...                                                  ...   \n",
              "39711  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
              "39712  [\"In python, implement a naive Bayes with gaus...   \n",
              "39713  [\"is it unethical to work on building weapons?...   \n",
              "39714  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
              "39715  [\"three kids eat three apples in three days, h...   \n",
              "\n",
              "                                                  chosen  \\\n",
              "0      [\"The question of whether it is morally right ...   \n",
              "1      [\"A marriage license and a marriage certificat...   \n",
              "2      [\"Creating a test set for a very rare category...   \n",
              "3      [\"The best way to travel from Tel-Aviv to Jeru...   \n",
              "4      [\"(Verse 1 - Zeus)\\n\\nI'm the king of the gods...   \n",
              "...                                                  ...   \n",
              "39711  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
              "39712  [\"Here is an implementation of a naive Bayes c...   \n",
              "39713  [\"Working on weapons technology raises some et...   \n",
              "39714  [\"As an AI language model, I do not promote or...   \n",
              "39715                                      [\"27 apples\"]   \n",
              "\n",
              "                                                rejected  \n",
              "0      [\"As an AI, I don't have personal beliefs or o...  \n",
              "1      [\"A marriage license is a legal document that ...  \n",
              "2      [\"When building a classifier for a very rare c...  \n",
              "3      [\"The best way to travel from Tel Aviv to Jeru...  \n",
              "4      [\"[Zeus]\\nYo, it's the king of the gods on the...  \n",
              "...                                                  ...  \n",
              "39711  [\"Here is how that mnemonic represents the dig...  \n",
              "39712  [\"Sure! Here's an implementation of a naive Ba...  \n",
              "39713  [\"It depends on the context. Weapons can be us...  \n",
              "39714  [\"Bromadiolone is a rodenticide which is most ...  \n",
              "39715  [\"If three kids eat three apples in three days...  \n",
              "\n",
              "[39716 rows x 3 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_train = train[['prompt','chosen','rejected']]\n",
        "new_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMbAIl2JveqP",
        "outputId": "3b3140bf-8417-45a8-bc96-f68a2cf485d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-d8139dda7f0d>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_train[\"prompt\"] = new_train[\"prompt\"].apply(lambda x: json.loads(x)[0])\n",
            "<ipython-input-13-d8139dda7f0d>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_train[\"chosen\"] = new_train[\"chosen\"].apply(lambda x: json.loads(x)[0])\n",
            "<ipython-input-13-d8139dda7f0d>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_train[\"rejected\"] = new_train[\"rejected\"].apply(lambda x: json.loads(x)[0])\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "new_train[\"prompt\"] = new_train[\"prompt\"].apply(lambda x: json.loads(x)[0])\n",
        "new_train[\"chosen\"] = new_train[\"chosen\"].apply(lambda x: json.loads(x)[0])\n",
        "new_train[\"rejected\"] = new_train[\"rejected\"].apply(lambda x: json.loads(x)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nruxAUYz3jq-"
      },
      "outputs": [],
      "source": [
        "new_train = new_train.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzlsEns8yVF_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_dat, val_dat = train_test_split(new_train, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dat = train_dat.reset_index(drop=True)\n",
        "val_dat = val_dat.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8gCW0cO1uSo"
      },
      "outputs": [],
      "source": [
        "train_dat = train_dat.drop(7512, axis = 0)\n",
        "train_dat = train_dat.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxb4vH_21uVC"
      },
      "outputs": [],
      "source": [
        "val_dat = val_dat.drop(1428, axis = 0)\n",
        "val_dat = val_dat.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m_Ws3JeyVR_",
        "outputId": "7e11ca13-f8f6-482e-fe04-fdc7c06c01ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'chosen', 'rejected'],\n",
              "    num_rows: 31753\n",
              "})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dat = Dataset.from_pandas(train_dat)\n",
        "train_dat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ3udtfJsIsZ",
        "outputId": "6d5a066b-fe5c-4f5e-b706-0bf683ac631f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'chosen', 'rejected'],\n",
              "    num_rows: 7938\n",
              "})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_dat = Dataset.from_pandas(val_dat)\n",
        "val_dat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrM6IARww-j2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Xk-sB9ziL1"
      },
      "source": [
        "# Training DPO Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "3e21bc30b09045208354f992a3c875d6",
            "f3c51625c9a641f7a66c0b146acdd441",
            "8f55ee660b6e47288225bab274ddb856",
            "82df653994bd48e28ad8d508c752fcf9",
            "a0d30a714a214ecbae30ae97dc57f1df",
            "d9b8713c4a0b447ab48436986e5833d9",
            "89dc24b55d0443a9b8e04967f4df6f15",
            "67084d8fa3e142af9cfc20bb0b53dfa7",
            "518fe28eaf14419082ca5cd16ec3c7c9",
            "f1b2975b587d47319ac190e0e885513a",
            "d4d31c0fb36f4760b5d8720b7fbde5dd"
          ]
        },
        "id": "CjuW65gCsIqD",
        "outputId": "cd504be4-4079-4793-b113-6d84246144a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e21bc30b09045208354f992a3c875d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# quantization_config = GPTQConfig(\n",
        "#     bits=4,\n",
        "#     dataset=\"wikitext2\",\n",
        "#     disable_exllama=True\n",
        "# )\n",
        "\n",
        "# 모델 로드\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelname,\n",
        "    quantization_config=quantization_config\n",
        ")\n",
        "\n",
        "# model_ref = AutoModelForCausalLM.from_pretrained(\n",
        "#     modelname,\n",
        "#     quantization_config=quantization_config\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t96C5p8ix2ns"
      },
      "outputs": [],
      "source": [
        "# model.push_to_hub(\"dongseon/kaggle_mistral-quant\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fRMhX9MpGBI"
      },
      "outputs": [],
      "source": [
        "# model_name = \"dongseon/kaggle_mistral-quant\"\n",
        "\n",
        "# quantization_config = GPTQConfig(\n",
        "#     bits=4,\n",
        "#     dataset=\"wikitext2\",\n",
        "#     disable_exllama=True\n",
        "# )\n",
        "\n",
        "# # 모델 로드\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     model_name,\n",
        "#     torch_dtype=torch.float16,\n",
        "#     low_cpu_mem_usage=True,\n",
        "#     quantization_config=quantization_config\n",
        "# )\n",
        "\n",
        "# model_ref = AutoModelForCausalLM.from_pretrained(\n",
        "#     model_name,\n",
        "#     torch_dtype=torch.float16,\n",
        "#     low_cpu_mem_usage=True,\n",
        "#     quantization_config=quantization_config\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TMZMRVMx-dj"
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=8,\n",
        "        lora_dropout=0.1,\n",
        "        target_modules=[\"o_proj\", \"v_proj\"],\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "peft_config.inference_mode = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7oxc0oQyAdi"
      },
      "outputs": [],
      "source": [
        "model = prepare_model_for_kbit_training(model)\n",
        "model.config.use_cache=False\n",
        "model.gradient_checkpointing_enable()\n",
        "model.config.pretraining_tp=1\n",
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZaDQofEyEgk"
      },
      "outputs": [],
      "source": [
        "# model_ref = prepare_model_for_kbit_training(model_ref)\n",
        "# model_ref.config.use_cache=False\n",
        "# model_ref.gradient_checkpointing_enable()\n",
        "# model_ref.config.pretraining_tp=1\n",
        "# model_ref = get_peft_model(model_ref, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTMLbdzvyC21",
        "outputId": "24d46eda-f905-487f-93dd-a5d54eeaf309"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): MistralForCausalLM(\n",
              "      (model): MistralModel(\n",
              "        (embed_tokens): Embedding(32768, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x MistralDecoderLayer(\n",
              "            (self_attn): MistralAttention(\n",
              "              (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (rotary_emb): MistralRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): MistralMLP(\n",
              "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): MistralRMSNorm()\n",
              "            (post_attention_layernorm): MistralRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): MistralRMSNorm()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHdhdQUjyGvi"
      },
      "outputs": [],
      "source": [
        "from trl import DPOConfig\n",
        "\n",
        "training_args = DPOConfig(\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    # max_steps=50,\n",
        "    remove_unused_columns=False,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=2e-5,\n",
        "    eval_strategy=\"steps\",\n",
        "    logging_first_step=True,\n",
        "    logging_steps=10,\n",
        "    output_dir=\"dongseon/kaggle_mistral-dpo\",\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    warmup_steps=2,\n",
        "    fp16=True,\n",
        "    # push_to_hub=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "2b69fd9483714dc3b7d079ca73c49b58",
            "5991a7c8ee20459984d5a85b5c0e52f2",
            "37a80c70ec744cbd9139cdd070168e4f",
            "4920f05a25d641208ab4801fda1a33aa",
            "fad53ea590bb49d8808d1c33e1f68f2b",
            "e5a0f69f43b841d993383e2026017e5e",
            "f9a150b9074c45629a730b5834925089",
            "13d6f37fb15342fa9a71aef90c476620",
            "18a9084c930942dfa0e5ca97413d2516",
            "909c654f2bfe4da7b26f52e720130a48",
            "faf0e262de994137bee8d455bdbdbc11",
            "e38890a57fb14b118475733f9390903d",
            "1286a53735574ca5b22451856e9ce66d",
            "364ae175855c4992813a30cc9864b810",
            "11a046ac18614a86894f31469592debb",
            "9967d0294d27427e983411296c4a6b42",
            "a0101556661f42b5a391ec6a4684af6f",
            "746efe9dfbbc4e198685b87ca6554ca8",
            "93fda078803d446494a3d38d47ce86f5",
            "8d2939a5c15542ccba9bf90c8ce8a6e5",
            "e15cf352a725415f83bf4a81d4b2091d",
            "30e27f725915429f8772c879729d8172"
          ]
        },
        "id": "WY8MG9SvyJ5q",
        "outputId": "156220c6-bf03-4397-cc65-52ee6be04c5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_length, max_target_length, max_prompt_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in DPOTrainer, please use the DPOConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:358: UserWarning: You passed `max_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:371: UserWarning: You passed `max_prompt_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:384: UserWarning: You passed `max_target_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b69fd9483714dc3b7d079ca73c49b58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/31753 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e38890a57fb14b118475733f9390903d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7938 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dpo_trainer = DPOTrainer(\n",
        "        model,\n",
        "        # model_ref,\n",
        "        args=training_args,\n",
        "        beta=0.1,\n",
        "        train_dataset=train_dat,\n",
        "        eval_dataset=val_dat,\n",
        "        tokenizer=tokenizer,\n",
        "        max_length=384,\n",
        "        max_target_length=384,\n",
        "        max_prompt_length=384,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05XRt-7YZaO1",
        "outputId": "235574af-7bcd-40e3-c5d7-015d922ba321"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "-ZV71r51ylUV",
        "outputId": "f1ddadb9-9dec-43d3-89ad-e9399737c7f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='81' max='1324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  81/1324 2:45:45 < 43:28:10, 0.01 it/s, Epoch 0.06/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rewards/chosen</th>\n",
              "      <th>Rewards/rejected</th>\n",
              "      <th>Rewards/accuracies</th>\n",
              "      <th>Rewards/margins</th>\n",
              "      <th>Logps/rejected</th>\n",
              "      <th>Logps/chosen</th>\n",
              "      <th>Logits/rejected</th>\n",
              "      <th>Logits/chosen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.692600</td>\n",
              "      <td>0.691224</td>\n",
              "      <td>0.005151</td>\n",
              "      <td>0.001156</td>\n",
              "      <td>0.312521</td>\n",
              "      <td>0.003994</td>\n",
              "      <td>-80.685326</td>\n",
              "      <td>-92.052170</td>\n",
              "      <td>-2.493677</td>\n",
              "      <td>-2.521866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.691000</td>\n",
              "      <td>0.689345</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>-0.006161</td>\n",
              "      <td>0.319025</td>\n",
              "      <td>0.008061</td>\n",
              "      <td>-80.758499</td>\n",
              "      <td>-92.084679</td>\n",
              "      <td>-2.490178</td>\n",
              "      <td>-2.518502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.687000</td>\n",
              "      <td>0.686745</td>\n",
              "      <td>-0.006826</td>\n",
              "      <td>-0.020874</td>\n",
              "      <td>0.324564</td>\n",
              "      <td>0.014048</td>\n",
              "      <td>-80.905624</td>\n",
              "      <td>-92.171944</td>\n",
              "      <td>-2.485475</td>\n",
              "      <td>-2.513913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.689600</td>\n",
              "      <td>0.684452</td>\n",
              "      <td>-0.015749</td>\n",
              "      <td>-0.035650</td>\n",
              "      <td>0.325445</td>\n",
              "      <td>0.019900</td>\n",
              "      <td>-81.053391</td>\n",
              "      <td>-92.261177</td>\n",
              "      <td>-2.481327</td>\n",
              "      <td>-2.509869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.688800</td>\n",
              "      <td>0.682669</td>\n",
              "      <td>-0.026923</td>\n",
              "      <td>-0.051818</td>\n",
              "      <td>0.326955</td>\n",
              "      <td>0.024895</td>\n",
              "      <td>-81.215065</td>\n",
              "      <td>-92.372902</td>\n",
              "      <td>-2.477535</td>\n",
              "      <td>-2.506176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.680700</td>\n",
              "      <td>0.680100</td>\n",
              "      <td>-0.045573</td>\n",
              "      <td>-0.077744</td>\n",
              "      <td>0.327711</td>\n",
              "      <td>0.032171</td>\n",
              "      <td>-81.474327</td>\n",
              "      <td>-92.559410</td>\n",
              "      <td>-2.476197</td>\n",
              "      <td>-2.504914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.681000</td>\n",
              "      <td>0.677108</td>\n",
              "      <td>-0.083879</td>\n",
              "      <td>-0.126440</td>\n",
              "      <td>0.325990</td>\n",
              "      <td>0.042561</td>\n",
              "      <td>-81.961288</td>\n",
              "      <td>-92.942467</td>\n",
              "      <td>-2.473298</td>\n",
              "      <td>-2.502063</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='172' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [172/331 11:24 < 10:36, 0.25 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='81' max='1324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  81/1324 2:45:45 < 43:28:10, 0.01 it/s, Epoch 0.06/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rewards/chosen</th>\n",
              "      <th>Rewards/rejected</th>\n",
              "      <th>Rewards/accuracies</th>\n",
              "      <th>Rewards/margins</th>\n",
              "      <th>Logps/rejected</th>\n",
              "      <th>Logps/chosen</th>\n",
              "      <th>Logits/rejected</th>\n",
              "      <th>Logits/chosen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.692600</td>\n",
              "      <td>0.691224</td>\n",
              "      <td>0.005151</td>\n",
              "      <td>0.001156</td>\n",
              "      <td>0.312521</td>\n",
              "      <td>0.003994</td>\n",
              "      <td>-80.685326</td>\n",
              "      <td>-92.052170</td>\n",
              "      <td>-2.493677</td>\n",
              "      <td>-2.521866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.691000</td>\n",
              "      <td>0.689345</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>-0.006161</td>\n",
              "      <td>0.319025</td>\n",
              "      <td>0.008061</td>\n",
              "      <td>-80.758499</td>\n",
              "      <td>-92.084679</td>\n",
              "      <td>-2.490178</td>\n",
              "      <td>-2.518502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.687000</td>\n",
              "      <td>0.686745</td>\n",
              "      <td>-0.006826</td>\n",
              "      <td>-0.020874</td>\n",
              "      <td>0.324564</td>\n",
              "      <td>0.014048</td>\n",
              "      <td>-80.905624</td>\n",
              "      <td>-92.171944</td>\n",
              "      <td>-2.485475</td>\n",
              "      <td>-2.513913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.689600</td>\n",
              "      <td>0.684452</td>\n",
              "      <td>-0.015749</td>\n",
              "      <td>-0.035650</td>\n",
              "      <td>0.325445</td>\n",
              "      <td>0.019900</td>\n",
              "      <td>-81.053391</td>\n",
              "      <td>-92.261177</td>\n",
              "      <td>-2.481327</td>\n",
              "      <td>-2.509869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.688800</td>\n",
              "      <td>0.682669</td>\n",
              "      <td>-0.026923</td>\n",
              "      <td>-0.051818</td>\n",
              "      <td>0.326955</td>\n",
              "      <td>0.024895</td>\n",
              "      <td>-81.215065</td>\n",
              "      <td>-92.372902</td>\n",
              "      <td>-2.477535</td>\n",
              "      <td>-2.506176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.680700</td>\n",
              "      <td>0.680100</td>\n",
              "      <td>-0.045573</td>\n",
              "      <td>-0.077744</td>\n",
              "      <td>0.327711</td>\n",
              "      <td>0.032171</td>\n",
              "      <td>-81.474327</td>\n",
              "      <td>-92.559410</td>\n",
              "      <td>-2.476197</td>\n",
              "      <td>-2.504914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.681000</td>\n",
              "      <td>0.677108</td>\n",
              "      <td>-0.083879</td>\n",
              "      <td>-0.126440</td>\n",
              "      <td>0.325990</td>\n",
              "      <td>0.042561</td>\n",
              "      <td>-81.961288</td>\n",
              "      <td>-92.942467</td>\n",
              "      <td>-2.473298</td>\n",
              "      <td>-2.502063</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='234' max='331' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [234/331 15:33 < 06:28, 0.25 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dpo_trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E097n7jfTeh"
      },
      "outputs": [],
      "source": [
        "dpo_trainer.push_to_hub(\"dongseon/kaggle_mistral-dpo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MIDJuc55L89"
      },
      "outputs": [],
      "source": [
        "\n",
        "# GPU 메모리 비우기\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BiUY7e5m8HC"
      },
      "source": [
        "# Preprocessing for Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWv2bskIm8a3",
        "outputId": "05c93f9e-582d-42b2-d659-4b99a4d88e8b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 57477,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1238326827,\n        \"min\": 30192,\n        \"max\": 4294947231,\n        \"num_unique_values\": 57477,\n        \"samples\": [\n          2785062085,\n          48259531,\n          3622731894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_a\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"mistral-7b-instruct\",\n          \"guanaco-33b\",\n          \"gpt-4-1106-preview\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_b\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"llama2-70b-steerlm-chat\",\n          \"llama-13b\",\n          \"gpt-4-0613\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51734,\n        \"samples\": [\n          \"[\\\"Are autoregressive language models (e.g. GPT-3) currently more popular than auto-encoding language models (e.g. BERT)? If so, what are the explanations?\\\"]\",\n          \"[\\\"Write a c++ algorithm that aims to find the rightmost zero in a binary representation, flip it to a one, and flip any 1s to its right\\\"]\",\n          \"[\\\"What is J\\\\u00e9r\\\\u00f4me WAX ?\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56566,\n        \"samples\": [\n          \"[\\\"Tea is grown commercially in the Azores, an autonomous region of Portugal. The main tea-producing estates are located on the island of S\\\\u00e3o Miguel, where the only commercial tea plantations in Europe can be found. The most well-known tea estates on S\\\\u00e3o Miguel are Gorreana Tea Estate and Porto Formoso Tea Factory.\\\"]\",\n          \"[\\\"Sure! Here's an example to illustrate how function pointers work in C:\\\\n\\\\n```c\\\\n#include <stdio.h>\\\\n\\\\n\\\\/\\\\/ Function to be pointed to\\\\nint add(int a, int b) {\\\\n    return a + b;\\\\n}\\\\n\\\\n\\\\/\\\\/ Function to demonstrate function pointers\\\\nvoid functionPointerExample(int (*funcPtr)(int, int)) {\\\\n    int result = funcPtr(5, 10);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n}\\\\n\\\\nint main() {\\\\n    \\\\/\\\\/ Use the address-of operator (&) to get the address of the add function\\\\n    int (*addPtr)(int, int) = &add;\\\\n\\\\n    \\\\/\\\\/ Call the functionPointerExample function and pass the address of the add function\\\\n    functionPointerExample(addPtr);\\\\n\\\\n    \\\\/\\\\/ Call the add function directly\\\\n    int result = add(15, 20);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n\\\\n    return 0;\\\\n}\\\\n```\\\\n\\\\nIn this example, we define a function `add` that takes two integers as arguments and returns their sum.\\\\n\\\\nWe then define a function `functionPointerExample` that takes a function pointer as an argument. This function calls the pointed-to function passing it two integers, and then prints the result.\\\\n\\\\nIn the main function, we create a function pointer `addPtr` which points to the `add` function. We then call the `functionPointerExample` function passing the address of the `add` function using the `&` operator.\\\\n\\\\nFinally, we call the `add` function directly and store the result in a variable `result`.\\\\n\\\\nI hope this helps you understand how function pointers work in C! Let me know if you have any other questions.\\\",\\\"To define a function pointer within a struct, you can define a member variable of the struct as a pointer to a function with a specific return type and argument list. Here's an example:\\\\n\\\\n```c\\\\n#include <stdio.h>\\\\n\\\\n\\\\/\\\\/ Define a structure with a function pointer member\\\\ntypedef struct {\\\\n    int (*calculate)(int);\\\\n} Calculator;\\\\n\\\\n\\\\/\\\\/ Function to be pointed to\\\\nint add(int num) {\\\\n    return num + 10;\\\\n}\\\\n\\\\n\\\\/\\\\/ Function to demonstrate using a function pointer within a struct\\\\nvoid useCalculator(Calculator calculator) {\\\\n    int result = calculator.calculate(15);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n}\\\\n\\\\nint main() {\\\\n    \\\\/\\\\/ Create a Calculator struct and initialize the function pointer member\\\\n    Calculator calculator = { add };\\\\n\\\\n    \\\\/\\\\/ Call the useCalculator function and pass the calculator struct\\\\n    useCalculator(calculator);\\\\n\\\\n    return 0;\\\\n}\\\\n```\\\\n\\\\nIn this example, we define a `typedef` for our `Calculator` struct, which has a single member `calculate` that is a pointer to a function that takes an integer as an argument and returns an integer.\\\\n\\\\nWe then define a function `add` that adds 10 to the input integer and return the result.\\\\n\\\\nWe define a function `useCalculator` that takes a `Calculator` struct as an argument and invokes the `calculate` member function of the struct with an argument of 15.\\\\n\\\\nIn the `main` function, we create a `Calculator` struct and initialize its `calculate` member with the address of the `add` function. We then call the `useCalculator` function passing the `calculator` struct.\\\\n\\\\nI hope this helps you understand how to define a function pointer within a struct in C! Let me know if you have any other questions.\\\"]\",\n          \"[\\\"In the depths of a dark and mysterious cave, there lived a heavily pregnant cavewoman named Ula. Her thick, matted hair cascaded down her back, and her skin was tanned and rough from years of living in the harsh wilderness. Ula's husband, Kadan, was a skilled hunter and provided for their small tribe. But lately, even his sharpest arrows seemed to fall short, and food had become scarce.\\\\n\\\\nUla felt a deep ache in her bones and her swollen belly. It was the third trimester, and her baby was growing rapidly. She wondered if she would ever be able to give birth in the cramped, narrow cave. Ula's tribe had no midwife, and her only hope was to rely on the wisdom passed down from her own mother.\\\\n\\\\nOne day, while Kadan was out hunting, Ula went into labor. Her screams echoed through the cave, and her tribe gathered around her in a frenzy. Ula's eyes widened as she felt the intense pain of contractions. She was afraid for her baby's life and her own.\\\\n\\\\nThe tribe tried to comfort Ula, but their efforts fell short. Ula's baby was too big, and the birth seemed impossible. Hours passed, and Ula lost all strength. Her tribe watched in horror as Ula's life slipped away. Suddenly, a loud cry broke the silence. Ula's baby had been born, and he was healthy and strong.\\\\n\\\\nThe tribe rejoiced at the sight of the newborn. They named him Kade, after Ula's husband, Kadan. Kade was a symbol of hope and resilience, and his birth brought new life and energy to the tribe.\\\\n\\\\nAs Ula took her last breath, she whispered to Kade, \\\\\\\"May you grow up to be a fierce and proud caveman, just like your father.\\\\\\\" Ula's legacy lived on through her son, and her tribe honored her memory by carving her name into the walls of the cave. The story of Ula, the heavily pregnant cavewoman who defied death to give birth to Kade, became a legend that would be passed down through the generations.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56609,\n        \"samples\": [\n          \"[\\\"Unfortunately, I do not have enough context to provide specific details about \\\\\\\"mobility123\\\\\\\" in New Jersey. Mobility123 is not a term I am familiar with. To provide more useful information, it would be helpful if you could clarify what kind of service, company, or product mobility123 refers to, as well as any additional details about what you would like to know in relation to New Jersey. Please provide some more context and details so that I can try to assist. Let me know if you can share more information!\\\"]\",\n          \"[\\\"Abby, Amber, Amra, Arin, Arna, Ashy, Bari, Bett, Brix, Bryn, Brin, Brynne, Ciri, Cyrn, Ebby, Ebri, Elbr, Elmry, Embr, Raby, Reba\\\"]\",\n          \"[\\\"It's great that your child is considering how to communicate with her friends in a way that doesn't upset them. Here are some tips that may help:\\\\n\\\\n1. Listen actively: Encourage your child to listen to her friends without interrupting or judging them. This means paying attention to what they're saying, asking questions to clarify their thoughts, and acknowledging their feelings.\\\\n2. Use kind words: Remind your child to use kind and respectful language when talking to her friends. This means avoiding hurtful words or tone, and being mindful of how her words may be perceived by others.\\\\n3. Be empathetic: Encourage your child to try to see things from her friends' perspective and to understand their feelings and needs. This means putting herself in their shoes and considering how they might be feeling.\\\\n4. Avoid gossip: Remind your child that gossiping about her friends can be hurtful and damaging to their relationships. Encourage her to avoid talking about her friends behind their backs and to speak to them directly if she has concerns.\\\\n5. Be honest: Remind your child that honesty is always the best policy, even if it's difficult to hear. Encourage her to be open and truthful with her friends, but also to be gentle and considerate in how she delivers her message.\\\\n\\\\nBy following these tips, your child can learn how to communicate effectively with her friends without upsetting them.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_tie\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-07e9269b-33c0-49ec-9d12-e11b60e228e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"Is it morally right to try to have a certain...</td>\n",
              "      <td>[\"The question of whether it is morally right ...</td>\n",
              "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"What is the difference between marriage lice...</td>\n",
              "      <td>[\"A marriage license is a legal document that ...</td>\n",
              "      <td>[\"A marriage license and a marriage certificat...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[\"explain function calling. how would you call...</td>\n",
              "      <td>[\"Function calling is the process of invoking ...</td>\n",
              "      <td>[\"Function calling is the process of invoking ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[\"How can I create a test set for a very rare ...</td>\n",
              "      <td>[\"Creating a test set for a very rare category...</td>\n",
              "      <td>[\"When building a classifier for a very rare c...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
              "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
              "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07e9269b-33c0-49ec-9d12-e11b60e228e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07e9269b-33c0-49ec-9d12-e11b60e228e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07e9269b-33c0-49ec-9d12-e11b60e228e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-549e4afb-6b90-499c-acf6-17f1970d7f6e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-549e4afb-6b90-499c-acf6-17f1970d7f6e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-549e4afb-6b90-499c-acf6-17f1970d7f6e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       id             model_a              model_b  \\\n",
              "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1   53567           koala-13b           gpt-4-0613   \n",
              "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [\"Is it morally right to try to have a certain...   \n",
              "1  [\"What is the difference between marriage lice...   \n",
              "2  [\"explain function calling. how would you call...   \n",
              "3  [\"How can I create a test set for a very rare ...   \n",
              "4  [\"What is the best way to travel from Tel-Aviv...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [\"The question of whether it is morally right ...   \n",
              "1  [\"A marriage license is a legal document that ...   \n",
              "2  [\"Function calling is the process of invoking ...   \n",
              "3  [\"Creating a test set for a very rare category...   \n",
              "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
              "1  [\"A marriage license and a marriage certificat...               0   \n",
              "2  [\"Function calling is the process of invoking ...               0   \n",
              "3  [\"When building a classifier for a very rare c...               1   \n",
              "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  \n",
              "0               0           0  \n",
              "1               1           0  \n",
              "2               0           1  \n",
              "3               0           0  \n",
              "4               1           0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve0SuMlum8di"
      },
      "outputs": [],
      "source": [
        "clf_train = train[['prompt','response_a','response_b','winner_model_a','winner_model_b','winner_tie']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ru3Tw8m8gJ",
        "outputId": "291ce644-db18-40fb-99a7-f03410dcc4d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-6d6c27551bad>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clf_train[\"prompt\"] = clf_train[\"prompt\"].apply(lambda x: json.loads(x)[0])\n",
            "<ipython-input-12-6d6c27551bad>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clf_train[\"response_a\"] = clf_train[\"response_a\"].apply(lambda x: json.loads(x)[0])\n",
            "<ipython-input-12-6d6c27551bad>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clf_train[\"response_b\"] = clf_train[\"response_b\"].apply(lambda x: json.loads(x)[0])\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "clf_train[\"prompt\"] = clf_train[\"prompt\"].apply(lambda x: json.loads(x)[0])\n",
        "clf_train[\"response_a\"] = clf_train[\"response_a\"].apply(lambda x: json.loads(x)[0])\n",
        "clf_train[\"response_b\"] = clf_train[\"response_b\"].apply(lambda x: json.loads(x)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Cgpx8gLwV1D"
      },
      "outputs": [],
      "source": [
        "clf_train = clf_train.dropna()\n",
        "clf_train = clf_train.reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a58bSx2Xm8lj"
      },
      "outputs": [],
      "source": [
        "clf_train['new_text'] = [ \"### prompt: \"+clf_train['prompt'][x]+\" ### response_a: \"+clf_train['response_a'][x]+\" ### response_b: \"+clf_train['response_b'][x] for x in range(len(clf_train)) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXbD5w2xtXoi"
      },
      "outputs": [],
      "source": [
        "clf_train['target'] = [[clf_train['winner_model_a'][x],clf_train['winner_model_b'][x],clf_train['winner_tie'][x]] for x in range(len(clf_train)) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGTnVeD5xxJ0"
      },
      "outputs": [],
      "source": [
        "clf_train = clf_train[['new_text','target']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoFNhaWQm8jF",
        "outputId": "1439fcf2-5242-4b20-d603-c21bf8fee3a5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"clf_train\",\n  \"rows\": 57439,\n  \"fields\": [\n    {\n      \"column\": \"new_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 57300,\n        \"samples\": [\n          \"### prompt: Teach me yolo8 and it's  code for beginners  ### response_a: YOLO (You Only Look Once) is a popular object detection algorithm, and YOLOv8 is the latest version. Here is an example code for a YOLOv8 model for beginners:\\n```python\\n# Import required libraries\\nimport tensorflow as tf\\nimport numpy as np\\n\\n# Import YOLOv8 model\\nfrom yolov8_model import YOLOv8\\n\\n# Create the model\\nmodel = YOLOv8('yolov8s')\\n\\n# Define the input shape\\ninput_shape = (416, 384, 1024, 1024)\\n\\n# Run inference on a sample input\\ninput_tensor = tf.random.normal((1, *input_shape))\\noutput = model(input_tensor)\\n\\n# Visualize the output\\nimport matplotlib.pyplot as plt\\n\\n# Unpack the output\\ny_pred = output.logits\\nx_pred = y_pred.detection_boxes\\ny_pred_class = y_pred.detection_classes\\nx_pred_box = x_pred.detection_boxes\\n\\n# Loop through the predictions\\nfor i in range(len(y_pred_class)):\\n    x_box = x_pred_box[i]\\n    y_box = y_pred_box[i]\\n    class_id = y_pred_class[i]\\n    score = y_pred_class[i]\\n    label = 'object detection'\\n    if score > 0.5:\\n        x, y, w, h = x_box\\n        x, y, w, h = map(int, [x, y, w, h])\\n        x, y, w, h = map(lambda x: x - 10, [x, y, w, h])\\n        x, y, w, h = map(int, [x, y, w, h])\\n        x, y, w, h = map(lambda x: x + 10, [x, y, w, h])\\n        x, y, w, h = map(int, [x, y, w, h])\\n        x, y, w, h = map(lambda x: x - w/2, ### response_b: Here is a basic introduction to YOLOv8 and object detection using YOLO for beginners:\\n\\nWhat is YOLOv8?\\n- YOLOv8 stands for You Only Look Once, version 8. It is an algorithm for real-time object detection in images and videos.\\n\\n- YOLOv8 is an improved version of the original YOLO object detection model. It achieves state-of-the-art accuracy while being faster than previous versions.\\n\\nHow does YOLOv8 work?\\n- YOLO divides an image into a grid of cells. Each grid cell predicts bounding boxes and class probabilities for objects in that cell. \\n\\n- The grid cells predict multiple bounding boxes. Each box encodes an objectness score (probability that the box contains an object), class probabilities, and box coordinates.\\n\\n- YOLOv8 utilizes techniques like feature pyramid networks, path aggregation networks, and self-attention to improve accuracy. It can detect over 80 classes in real-time.\\n\\nUsing YOLOv8 for object detection:\\n- Download a pre-trained YOLOv8 model weights file. Common file formats are .weights or .pt.\\n\\n- Use a deep learning framework like PyTorch or TensorFlow to load the model. Define model, loss and optimizer.\\n\\n- Load your dataset images and preprocess them to match model requirements (size, normalization etc). \\n\\n- Pass images through the model to obtain predictions. Decode predictions to get bounding boxes and class labels.\\n\\n- Evaluate model on validation set using metrics like mAP to check performance. Retrain if needed with your dataset. \\n\\n- Integrate model into applications for real-time object detection in images, videos or live camera feeds.\\n\\nThat's a basic overview of YOLOv8 for beginners. Let me know if any part needs more explanation!\",\n          \"### prompt: Write a two-sentence horror story ### response_a: Here is a two-sentence horror story:\\n\\nI was home alone one night when I heard a noise coming from the attic. As I slowly walked up the stairs, the tapping sound got louder and louder until it was right above me. ### response_b: The last person on Earth was happy until there was a knock at the door.\\nShe awoke to the sound of labored breathing and realized it was her own.\",\n          \"### prompt: what is \\\"Bloodborne PSX\\\" ### response_a: \\\"Bloodborne PSX\\\" is a fan-made project that aims to create a modified version of the popular game \\\"Bloodborne\\\" to run on the original PlayStation console, which has significantly lower hardware capabilities than modern consoles. The project is not officially endorsed by Sony or FromSoftware, the developers of the original game, and it may not be legally distributable or playable on actual physical PSX consoles. The project is still in development, and its success is uncertain as it requires significant modifications to the game's code and graphics to make it compatible with the PSX hardware. ### response_b: \\\"Bloodborne PSX\\\" refers to the PlayStation Experience (PSX) event in 2014, where Bloodborne, an action-adventure horror video game, was officially revealed. The game was developed by FromSoftware and published by Sony Interactive Entertainment for the PlayStation 4. Bloodborne is set in the city of Yharnam, a dark and gothic setting, where players take on the role of a hunter seeking to uncover the secrets of the city and its cursed inhabitants. The game is part of the \\\"Souls\\\" series, which also includes Dark Souls and Demon's Souls, and is known for its challenging gameplay, intricate level design, and engaging lore.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "clf_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bd8833bc-a7d6-4479-943d-10224de0c562\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>new_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>### prompt: Is it morally right to try to have...</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>### prompt: What is the difference between mar...</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>### prompt: explain function calling. how woul...</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>### prompt: How can I create a test set for a ...</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>### prompt: What is the best way to travel fro...</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd8833bc-a7d6-4479-943d-10224de0c562')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd8833bc-a7d6-4479-943d-10224de0c562 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd8833bc-a7d6-4479-943d-10224de0c562');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7c2009db-3143-42a8-a7f4-6978d9b9640a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c2009db-3143-42a8-a7f4-6978d9b9640a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7c2009db-3143-42a8-a7f4-6978d9b9640a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            new_text     target\n",
              "0  ### prompt: Is it morally right to try to have...  [1, 0, 0]\n",
              "1  ### prompt: What is the difference between mar...  [0, 1, 0]\n",
              "2  ### prompt: explain function calling. how woul...  [0, 0, 1]\n",
              "3  ### prompt: How can I create a test set for a ...  [1, 0, 0]\n",
              "4  ### prompt: What is the best way to travel fro...  [0, 1, 0]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KZGV9ndum13"
      },
      "outputs": [],
      "source": [
        "\n",
        "def cl(x):\n",
        "  if x == [1,0,0]:\n",
        "    return 0\n",
        "  elif x == [0,1,0]:\n",
        "    return 1\n",
        "  else :\n",
        "    return 2\n",
        "\n",
        "clf_train['labels'] = clf_train['target'].apply(lambda x : cl(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS05Ol8atxem"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "t_dat, v_dat = train_test_split(clf_train, test_size=0.2, random_state=42, stratify = clf_train['labels'])\n",
        "\n",
        "t_dat = t_dat.reset_index(drop=True)\n",
        "v_dat = v_dat.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEKar6vttxhK"
      },
      "outputs": [],
      "source": [
        "t_dat = t_dat.drop( labels= 'target' , axis = 1)\n",
        "v_dat = v_dat.drop( labels= 'target' , axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWmg7St3txoo"
      },
      "outputs": [],
      "source": [
        "# t_dat = t_dat.iloc[:1000,:]\n",
        "# v_dat = v_dat.iloc[:100,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lqw7L4stxrV",
        "outputId": "f9ef399b-049b-4e70-8fd0-6e4482c33e26"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"t_dat\",\n  \"rows\": 45951,\n  \"fields\": [\n    {\n      \"column\": \"new_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 45854,\n        \"samples\": [\n          \"### prompt: Hello, I just had a thought: Can language model inference be enhanced by introducing multiple token reading frames analogous to how the DNA has three different reading frames? Sorry if this is a stupid question. ### response_a: Hello! Your question is not stupid at all. It's an interesting idea to explore.\\n\\nIn the context of DNA, the three different reading frames refer to the way that the sequence of nucleotides (A, C, G, and T) can be read in three different ways by starting at different points. Each reading frame produces a different sequence of amino acids, which in turn can produce different proteins. This is important for understanding how the genetic code is translated into functional proteins.\\n\\nIn the context of language models, the tokens (words, subwords, or characters) are typically read in a single linear sequence, with each token being processed one at a time. However, there are some ways in which the idea of multiple reading frames could potentially be applied to language models.\\n\\nOne possibility is to use multiple parallel sequences of tokens, each with a different offset or starting point. This could allow the model to capture different patterns or dependencies in the text that might be missed by processing the tokens in a single linear sequence. For example, the model could process the text in a sliding window of fixed size, with different windows offset by different amounts.\\n\\nAnother possibility is to use a multi-head attention mechanism, which is a common component of many transformer-based language models. Multi-head attention allows the model to attend to different parts of the input sequence simultaneously, effectively creating multiple \\\"reading frames\\\" that can capture different patterns or dependencies in the text.\\n\\nOverall, while the idea of multiple reading frames in language models is not a direct analogy to the genetic code, there are some ways in which the concept could be applied to improve the performance of language models. However, it would likely require careful experimentation and tuning to determine the best approach for a particular task or dataset. ### response_b: Your question is not stupid at all; it's quite imaginative and shows a good understanding of the analogy between biological processes and computational models. In DNA, a reading frame refers to the way nucleotides are divided into codons, which are then translated into amino acids. There are three possible reading frames in DNA, each shifted by one nucleotide from the last. This concept is crucial in biology because it can lead to entirely different proteins being produced from the same sequence of DNA, depending on where the translation process starts.\\n\\nIn natural language processing (NLP) and language models like GPT (Generative Pre-trained Transformer), tokens (which can be words or subwords) are already processed in a sequential manner that incorporates context from both the preceding and following tokens. Language models use complex patterns of attention to weigh various parts of the input text when predicting the next token. This process is quite different from the linear, non-overlapping reading frames in DNA translation.\\n\\nHowever, your suggestion of introducing multiple reading frames in language modeling is an interesting one. It could theoretically allow a model to explore alternative interpretations of a text by shifting the token alignments. Here's a simple illustration of how this could work:\\n\\n- Standard token sequence: \\\"The quick brown fox jumps over the lazy dog.\\\"\\n- Shifted by one token: \\\"quick brown fox jumps over the lazy dog The.\\\"\\n- Shifted by two tokens: \\\"brown fox jumps over the lazy dog The quick.\\\"\\n\\nEach of these sequences could be fed into a language model separately, and the model could potentially learn different things from each sequence. However, unlike DNA, where the reading frame is critical to producing the correct protein, in language, the meaning of words and sentences is highly dependent on order and syntax. Shifting words around arbitrarily would likely produce non-sensical results in most cases.\\n\\nThat said, there are some related concepts in NLP that explore alternative ways of understanding and generating text:\\n\\n1. **Ensembling**: Using multiple models or multiple runs of a model with different initial conditions to get a broader understanding of possible interpretations of a text.\\n   \\n2. **Data Augmentation**: Slightly altering the training data, for example by paraphrasing sentences or using synonyms, to make models more robust by exposing them to a wider variety of linguistic expressions.\\n\\n3. **Multi-task Learning**: Training a model on several different, but related, tasks simultaneously to improve its generalization capabilities.\\n\\n4. **Bidirectional Context**: Models like BERT look at text from both the left and the right, considering the context in both directions.\\n\\nWhile these techniques don't directly parallel the concept of reading frames in DNA, they represent ways in which NLP tries to capture the multifaceted nature of language. The concept of multiple reading frames could be a metaphorical inspiration for exploring alternative methods of text analysis, but the direct application of the concept may not be straightforward due to the inherent differences between genetic code and natural language.\",\n          \"### prompt: Design a board game based on the prisoner's dilemma and the coordination problem ### response_a: Game Title: \\\"Prisoner's Predicament\\\"\\n\\nGame Objective: The objective of the game is to score the highest number of points by making strategic decisions and coordinating actions with other players while navigating through a series of Prisoner's Dilemmas and Coordination Problem situations.\\n\\nNumber of Players: 4-6 players\\n\\nGame Components:\\n\\n1. Game Board: A circular board divided into 12 sections, each representing a different scenario (6 Prisoner's Dilemma scenarios and 6 Coordination Problem scenarios).\\n2. Player Tokens: Six tokens representing each player (different colors).\\n3. Score Sheets: Paper and pencil for keeping track of each player's score.\\n4. Decision Cards: Two sets of decision cards \\u2013 one set for Prisoner's Dilemma scenarios (Cooperate or Defect cards) and another set for Coordination Problem scenarios (Option A or Option B cards).\\n5. Six-sided Dice: Used to determine which scenario players will encounter.\\n6. Timer: A sand timer or digital timer to limit decision-making time.\\n\\nGameplay:\\n\\n1. Setup: Each player selects a token and places it on the starting space of the game board. Players decide the order of play.\\n2. Rolling the Dice: The first player rolls the dice to determine which scenario they will encounter. The number rolled corresponds to a scenario space on the game board.\\n3. Decision Time: Once the scenario space is determined, the player has 30 seconds (or a designated time) to secretly select a decision card from the appropriate set (Cooperate/Defect or Option A/Option B) and place it face down in front of them.\\n4. Revealing Decisions: After all players have made their decisions, they simultaneously reveal their chosen cards.\\n5. Scoring:\\n\\n   a. Prisoner's Dilemma:\\n      - If all players cooperate, they each receive 3 points.\\n      - If one player defects while the others cooperate, the defector receives 5 points, and the cooperators receive 0 points.\\n      - If all players defect, they each receive 1 point.\\n\\n   b. Coordination Problem:\\n      - If all players choose Option A, they each receive 4 points.\\n      - If all players choose Option B, they each receive 4 points.\\n      - If players choose a mix of both options, they each receive 0 points.\\n\\n6. Advancing on the Board: After scoring, all players move their tokens clockwise to the next scenario space. If a player lands on a space already occupied by another player's token, they \\\"bump\\\" that player back to the previous open space.\\n7. Winning the Game: The game continues until all players have visited each scenario space once. The player with the highest score at the end of the game wins. In case of a tie, the tied players share the victory.\\n\\nGame Strategy:\\n\\n- Players must strike a balance between cooperating and competing to maximize their scores.\\n- Building trust with other players can lead to higher rewards, but players must be cautious of potential betrayals.\\n- Players should also consider the order of play and how previous decisions may impact future scenarios. ### response_b: Title: \\\"Dilemma Dash\\\"\\n\\nObjective:\\nThe objective of \\\"Dilemma Dash\\\" is for players to strategize and cooperate to achieve the highest overall score while navigating through various dilemmas and coordination challenges.\\n\\nComponents:\\n1. Game Board: A grid-based board representing different scenarios and challenges.\\n2. Player Tokens: Each player has a unique token to move around the board.\\n3. Dilemma Cards: A deck of cards with different dilemmas and coordination challenges.\\n4. Score Trackers: Individual trackers to keep score for each player.\\n5. Decision Tokens: Tokens used to indicate player choices during dilemmas.\\n\\nGameplay:\\n1. Setup: Place the game board in the center of the playing area and distribute player tokens to each player. Shuffle the dilemma cards and place them face down as a draw pile. Each player places their score tracker on the starting point of the score track.\\n2. Turn Order: Players take turns clockwise.\\n\\n3. Movement Phase:\\n   a. Roll the dice or use a predetermined method to determine the number of spaces a player can move.\\n   b. Players can move their token in any direction on the board, but they cannot move diagonally or backtrack.\\n\\n4. Dilemma Phase:\\n   a. When a player lands on a dilemma space, they draw a card from the dilemma deck.\\n   b. The player reads the dilemma aloud and presents the options to the other players.\\n   c. Each player secretly selects their decision by placing a decision token face down.\\n   d. Once all players have made their decision, the tokens are revealed simultaneously.\\n\\n5. Scoring Phase:\\n   a. Each dilemma card has specific point values for different combinations of decisions made by the players.\\n   b. Players update their individual score trackers based on the outcome of the dilemma.\\n   c. The dilemma card is discarded, and play continues to the next player.\\n\\n6. Coordination Challenges:\\n   a. Some spaces on the game board will present coordination challenges instead of dilemmas.\\n   b. These challenges require players to work together and coordinate their movements to earn bonus points.\\n   c. Players must discuss and agree on a specific set of moves to successfully complete the challenge.\\n   d. If successful, players receive bonus points based on the challenge difficulty level.\\n\\n7. Game End:\\n   The game ends after a predetermined number of rounds or when all dilemma cards have been played. The player with the highest overall score wins the game. In case of a tie, the player with the most successful coordination challenges wins.\\n\\nOptional Variations:\\n- Cooperative Mode: Players work together as a team to achieve the highest cumulative score.\\n- Advanced Challenges: Introduce more complex coordination challenges to increase the difficulty level.\\n- Strategy Cards: Include additional cards that players can acquire to manipulate dilemmas or influence other players' decisions.\\n\\n\\\"Dilemma Dash\\\" encourages players to consider the consequences of their decisions and the benefits of cooperation while also challenging them with coordination problems. It provides an engaging and thought-provoking gaming experience that explores the concepts of the prisoner's dilemma and coordination problems.\",\n          \"### prompt: Proofread this:\\nDear Mila\\nThanks for your reply.\\n\\nAbout cold room wire shelving:\\nWe are busy designing the packaging. We send it to you once it\\u2019s done.\\n\\nAbout LED lights:\\nWe believe you can find a better price about $3 per piece. Could you please check if you could come up with a better price?\\nAnd we will skip the tables. So don\\u2019t worry about it.\\nWe also send you the packaging design once it\\u2019s done.\\n\\nAbout other products.\\nWe are happy with that. Please do not forget to add Pirouz whenever you can on the product.\\n\\nAbout M8 screws\\nM8x60mm in zinc plated is fine. Please send us a quotation. \\n\\nIf there is any question, please let us know.\\n\\nBest regards\\nArmand\\n ### response_a: Here are a few edits to the letter:\\n\\nDear Mila, \\n\\nThanks for your reply.\\n\\nAbout the cold room wire shelving:\\nWe are busy designing the packaging. We will send it to you once it\\u2019s done.\\n\\nAbout the LED lights:  \\nWe believe you may be able to find a better price of around $3 per piece. Could you please check if you could come up with a better price?\\nAnd we will skip the tables, so don't worry about them.\\nWe will also send you the packaging design once it's done.\\n\\nAbout other products:\\nWe are happy with that. Please do not forget to add \\\"Pirouz\\\" whenever possible on the products. \\n\\nAbout the M8 screws\\nM8x60mm in zinc plated is fine. Please send us a quotation.\\n\\nIf you have any other questions, please let me know.\\n\\nBest regards,\\nArmand ### response_b: Dear Mila,\\n\\nThanks for your reply.\\n\\nRegarding cold room wire shelving:\\nWe are currently designing the packaging. We will send it to you once it's completed.\\n\\nAbout LED lights:\\nWe believe you can find a better price at around $3 per piece. Could you please check if you can source a more competitive price? Also, we have decided to skip the tables. So, you don't need to worry about them. We will send you the packaging design once it's finalized.\\n\\nAbout other products:\\nWe are satisfied with the current state. Please ensure to include \\\"Pirouz\\\" on the product whenever possible.\\n\\nRegarding M8 screws:\\nZinc-plated M8x60mm is suitable. Please provide us with a quotation for this item.\\n\\nIf you have any questions or concerns, please do not hesitate to let us know.\\n\\nBest regards,\\nArmand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "t_dat"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-85e0f584-0eb8-41ff-a509-d9c87d449462\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>new_text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>### prompt: Can you tell another Richard Pryor...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>### prompt: paraphrase: \"Write a social media ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>### prompt: Hi there please help me write a ce...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>### prompt: funcion generatiu de moments d'una...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>### prompt: I'm interested in the sum from n= ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85e0f584-0eb8-41ff-a509-d9c87d449462')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85e0f584-0eb8-41ff-a509-d9c87d449462 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85e0f584-0eb8-41ff-a509-d9c87d449462');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-42188b3e-728a-4bde-96f4-60912d78976f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42188b3e-728a-4bde-96f4-60912d78976f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-42188b3e-728a-4bde-96f4-60912d78976f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            new_text  labels\n",
              "0  ### prompt: Can you tell another Richard Pryor...       2\n",
              "1  ### prompt: paraphrase: \"Write a social media ...       1\n",
              "2  ### prompt: Hi there please help me write a ce...       1\n",
              "3  ### prompt: funcion generatiu de moments d'una...       0\n",
              "4  ### prompt: I'm interested in the sum from n= ...       2"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_dat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XchO_cvqabUj",
        "outputId": "0d9eca4e-c453-46ae-bd76-47227d292d95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(t_dat['labels'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a562b110dabc458286f1cdd0ec05c9f2",
            "6bade884f4544c9db1e91c2bafc2a6ae",
            "2752561a16c6413c9be9fb41ec7b4669",
            "db4ea4f2dc8843429118177f383a166c",
            "4a003abec19447b3b183a4d1d1908825",
            "504e1f617ed14dfcad816d425c95044a",
            "838274c16d974c47a6ded0635dd273b8",
            "3dcf9c370d32403e890c8bfec439ea01",
            "9a7bb724379e4fe8b1de60ef79ce160a",
            "700e52b083da4fe5b2527957ae0ffe45",
            "bd30d213272e4d96acecb40388286a46",
            "21f1462768944694bc3717c7763579c2",
            "bcaea40435e5405b878c32d8bf703958",
            "70165e2d36eb41528777744d620ee131",
            "04aded80a5774429b982c87e93d2b4de",
            "dbb0088887664a5d84cc17a78bce2237",
            "5103eebc511d488db991271aba37c824",
            "a5ed04b16b2f45a29ea83dbff3d8ad6e",
            "3822e0b21d1948f4bfe3c505f82677b9",
            "b59d05df62ee4d66a91bb75cb1beb79f",
            "59a02a6927114fb99b6b532a5bf30d55",
            "c72e844242bc44e6a9a4bc403164b3d7",
            "44736b08e38443b28cdab42589cdbe9c",
            "639e04cb241b4504858b1631c379f530",
            "251e6f6aa144404bbbe8782a15d6dc64",
            "f492126461f04498b0c5e8640b2dcabc",
            "a71f067cdb2e40cba3a29b1b30617e71",
            "316bb133bc804887af8ec5aa4790218f",
            "5e23d8efd05c44698b454187584ba95c",
            "ac5bc036e2504f5b9ca48539fefc99e5",
            "05b62a95c4da482c8b5a903120685c08",
            "ce096d140c13473788d6d5c4ab7dfb63",
            "e88426f2e34344c983bac1e1af5be2f4",
            "28f2d0ddaae54e44899b54cd75aed050",
            "efd3813f39a74346ab411f73b678a057",
            "e3739cfbe01e49a99fa5c91ae3b85c21",
            "fde02c422e3c45498d2a03ede78f68ed",
            "a352253498d944019ee674691927537b",
            "2dc6842683d04de9b67e5db139eecba3",
            "948cec41b5ce4455835d9208359d8b52",
            "da24161c184c4a79889eada154f6240b",
            "77c5d4048969465ba0f078aeaf1002e4",
            "22a2774bfb4e4667acc353fbba392d10",
            "af77a15ad34f4b1b823aebad570dc404"
          ]
        },
        "id": "evd-GqDDzzik",
        "outputId": "a05f0099-811f-4b36-ee7d-b1549a7c91db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a562b110dabc458286f1cdd0ec05c9f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21f1462768944694bc3717c7763579c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44736b08e38443b28cdab42589cdbe9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28f2d0ddaae54e44899b54cd75aed050",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import GenerationConfig\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG59kYedtXtq"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.title = df['new_text']\n",
        "        self.targets = self.df['labels']\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'labels': torch.LongTensor([self.targets[index]])\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS5mRZYqtXwG"
      },
      "outputs": [],
      "source": [
        "max_len = 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOzrNAn20ntB"
      },
      "outputs": [],
      "source": [
        "# trainer api\n",
        "\n",
        "train_dataset = CustomDataset(t_dat, tokenizer, max_len)\n",
        "val_dataset = CustomDataset(v_dat, tokenizer, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC_t5aoy1Tya",
        "outputId": "a4781aa0-691a-4e93-a40c-678f34f261a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    1,   774, 11510,  ...,     2,     2,     2]),\n",
              " 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
              " 'labels': tensor([2])}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset.__getitem__(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMpf6Ru9tXrK",
        "outputId": "2aa6f60f-78d2-40a3-b5c1-1b7105cc5764"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<s>'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode([1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ztbBB1em8oC"
      },
      "outputs": [],
      "source": [
        "# low train\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "valid_data_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj4i5DufkTjx"
      },
      "source": [
        "# Training Classifier Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467,
          "referenced_widgets": [
            "0a5525077b164f2a95efb353b829d927",
            "91f6ce8e67964ec0b99c5b075e49cfd6",
            "d960a1ea14674c90b95c39b2b55c1aa7",
            "db7230f0d64c4b5b8771abdc46919da4",
            "0aa9411ea14747d99504fc6336f512f3",
            "df07d321191649b49472205cebea4aa0",
            "f28fc516581548e3b148bcb4add265cd",
            "9efd3dcf36624df0b674a2521a70daed",
            "e86481e42f8948399df8c37de3754a67",
            "45f1b83380464363afb134331ce4cc55",
            "5394e21a6d6e41af84e9d1aec7dff201",
            "181fd9d4d28c4cecba7e685b69fe9a90",
            "5975f80cfa3645528a0fd4b3f579631d",
            "48942655d62349abae6e8331c89d6277",
            "0d4bda61d3d04a349781ab2d2bf0d5bb",
            "afd7ee119fb445d286625f49ea8ae268",
            "a30f6291eec84eb6b66e2d7a201fefd4",
            "7ae6ac4fcfc5408aa42ce9faed94a1ff",
            "d68963bbe9ec4586ab7fed453b001290",
            "df95676707254ec8b765db7dea9293a2",
            "bd6dc9e4488348058069956aa6e7bf72",
            "a7788d690c9d45698f1f40a78716ca0c",
            "907b4e4a8160453aba9f6fb53e15ba26",
            "e651083693cd4f58a972fc3caa55049d",
            "9522c96d797b4daa886770f64a766eec",
            "6497b669aba14eb7b16e0ddabc193dbc",
            "bd8f0b8734b84c4286588b1b2235a2f7",
            "de552982a7814718a61614edf323b8cb",
            "751a6719f84847598942b32b052d592d",
            "b05b4cad090b473d818a9bfd4cb0671a",
            "a904d4f76efe4182ab32bee42f6d828d",
            "38f05d147c59436ca91c0462cbfab56d",
            "33782af3ee0d49a79097f07cbf3ba005",
            "5c7b9477caa54bfd9680ddeaf279f694",
            "72b30d5d6eec40f396c7cc47f63b99bf",
            "0df380689e8048a494c7dbfb9776b446",
            "1b866ed2b0544c069fdc0922d7f74fe3",
            "f3cdbc823928401f9673c8f7b6742fab",
            "1a3ab22097134b01b253e19edd77b51d",
            "e40e368e14584c3e97585190cc9d0cb8",
            "c09d8bd43cbe481cae460719a75f341e",
            "e196ce15d6c94736a9856699e431b944",
            "983258e7f35e4167bbf204c9cfbef6bc",
            "432ac55fb13849858476fd7142637efc",
            "7f6d86aaaf474687ae6ebe96c57f7e99",
            "5ec9ff2929ee47fb9ec1ac3aec6effed",
            "5479cd9f848e40e59bf3aebffc548e86",
            "2edd27009fd64446bad5efb9ce2394d5",
            "41964f83005445eab064da2788ab8948",
            "ef2f607cbfdb40a9b87745ac2d9046c3",
            "a6bfa24be9d0435f82603343ab530bcc",
            "a72b372c850641d9aad30ce8a784b81a",
            "8ded652f6b194d6db9c223671edda9df",
            "108011e9fdb3423d805c4478687cdf62",
            "e3e4ea448b70487d95c7157e50dbfd83",
            "3e5fb58c31114bcabe1b7c97af192964",
            "92b131f472f9477d8839c354bb03cc78",
            "b2f3974cdc69446fae8deff40af448fc",
            "de920037a30f45568b1bdee400752ae8",
            "431cd7ed6b81468b9e403584e58e17d1",
            "47d4c5607c75407db7572411d1536418",
            "104ef6e8c2cf4ce698a061847b2593d4",
            "7447ed86bd844b75b593e4a407d926a7",
            "88ae7eee3e044e4ea2ec9143ae723579",
            "16affd2ba0754498967f376cb693cade",
            "006fe2a82244405ab22436287120edcc",
            "b11e1b59c0eb43a5bb63b0aad4aa5fb4",
            "433205a50bf349bab53f939d3f465c7b",
            "a491ebb17db84c13b2f5c0ba85f48fba",
            "86aa45b9630e4fd0b27be2566387e5a9",
            "4a08ff8bf52c485d92a0176c35401260",
            "a340be79b62347b38bf6ce12586b96f0",
            "96a6151b07ef470e9be1e5dfd45f8566",
            "c5a8cafd713b4f4c9b8e7f15db3e9cb6",
            "fab6fb9e0e4c4253a16585f35e67e5c7",
            "079f753989054a85ad03aba375a15441",
            "f0af24af1e594499a7b31b43b5f00558",
            "a1b2c9577b4a48e395cfe41ec09610dc",
            "cf44965e965849d8bbbf8cc962038478",
            "328bb007f2ca45b9aab116dfecfa4aa6",
            "03acf0e3c5de4e498ccfdb6b24e22b64",
            "74664f5070bc4143bc41d0b15ba5d2e8",
            "5489d57115254e6db8f781f26252e0ba",
            "dd72152367b04806a82231e9febae878",
            "343029f37d804ead8af836d46c3fb98f",
            "42d2a594944847f2aa75d7469091d8db",
            "b91592c793664b01b5d56bf250da2bc1",
            "ba0253ece6bd4b3aa7bf2b6757091134",
            "1a77a932eec64199b16cc49ea317130e",
            "29135b7aa4b942189ad21c39b0020d75",
            "5330359946194b94862742cb1a164737",
            "8841c914e02f4425af085379179d5015",
            "6bafca1fa3f54475a0ee55a09e2c2a1d",
            "bf98a7ade2584433806c0879416807a5",
            "e831330e459d42a39a5f6f70d4d0f060",
            "a6c9cd78319f48f183058decb7f0d8d9",
            "6ac50861f97749eeb3a13c7eaa44d63e",
            "b410276c8e5143309db3c6ad545a912c",
            "1f4023cd87d14cbd92e97283616fb472",
            "63796cb8612a471f889801d46f2f2ec6",
            "658ba88f373246fb910651ec090ba222",
            "4defa628ed864b02826ed73520850c3b",
            "886eedbb79784b7ea5419bcc48611859",
            "72407fd5546847b98a7d605fbefe9db5",
            "336f2136b2b84bffb5b8814485122f38",
            "566dd04bce824f51bbfbacbfb230b1da",
            "c8448a26edbc462483e23758d6f3ac91",
            "2cb00b99bf5c48db9259bfb8556b2ff3",
            "a72267cb84294293854572a9ea9ad837",
            "eb8013c172384b0eaa4f4f542d6d60e9"
          ]
        },
        "id": "F_-sgP5MkWaO",
        "outputId": "7a9d8806-136a-4aee-8c6d-e88bf237c486"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a5525077b164f2a95efb353b829d927",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/652 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "181fd9d4d28c4cecba7e685b69fe9a90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda:CUDA extension not installed.\n",
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda_old:CUDA extension not installed.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "907b4e4a8160453aba9f6fb53e15ba26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/4.16G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4371: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c7b9477caa54bfd9680ddeaf279f694",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f6d86aaaf474687ae6ebe96c57f7e99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e5fb58c31114bcabe1b7c97af192964",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b11e1b59c0eb43a5bb63b0aad4aa5fb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1b2c9577b4a48e395cfe41ec09610dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a77a932eec64199b16cc49ea317130e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63796cb8612a471f889801d46f2f2ec6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/13.6M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BitsAndBytesConfig\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "model_name = \"dongseon/kaggle_mistral-dpo\"\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "class PeftModelForClassification(nn.Module):\n",
        "    def __init__(self, peft_model, config):  # config 추가\n",
        "        super(PeftModelForClassification, self).__init__()\n",
        "        self.config = config  # config 설정\n",
        "        self.peft_model = peft_model\n",
        "        self.dropout = torch.nn.Dropout(0.2)\n",
        "        self.classifier = nn.Linear(config.hidden_size, 3)  # config.hidden_size를 사용하여 linear layer 크기 설정\n",
        "        self.classifier.weight.data = self.classifier.weight.data.to(torch.float16)\n",
        "        self.classifier.bias.data = self.classifier.bias.data.to(torch.float16)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.peft_model(input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.hidden_states[-1]\n",
        "        pooled_output = hidden_states.mean(dim=1)\n",
        "        output_dropout = self.dropout(pooled_output)\n",
        "        logits = self.classifier(output_dropout)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "          labels = labels.squeeze()\n",
        "          loss = loss_fn(logits, labels)\n",
        "        return loss, logits\n",
        "\n",
        "peft_model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"cuda\",\n",
        "    output_hidden_states=True,\n",
        "\n",
        ")\n",
        "\n",
        "# PEFT 모델에 분류기 추가할 때 config도 전달\n",
        "model = PeftModelForClassification(peft_model, peft_model.config).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tMn0iVPlqTB"
      },
      "outputs": [],
      "source": [
        "# 분류기를 제외한 모든 가중치 프리징\n",
        "for param in model.peft_model.parameters():\n",
        "    param.requires_grad = False\n",
        "# for param in model.classifier.parameters():\n",
        "#     param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiphPSRTZs5K",
        "outputId": "03af9730-03d1-43f8-ba25-943c078289b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total trainable parameters: 12291\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad == True)\n",
        "print(f\"Total trainable parameters: {total_params}\")\n",
        "# Total trainable parameters: 12291"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OyYfPk5Z9BT",
        "outputId": "c79ec7e1-d9e5-4001-9b8d-d6a576baa114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter name: peft_model.base_model.model.model.embed_tokens.weight, Shape: torch.Size([32000, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.0.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.0.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.1.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.1.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.2.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.2.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.3.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.3.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.4.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.4.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.5.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.5.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.6.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.6.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.7.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.7.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.8.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.8.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.9.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.9.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.10.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.10.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.11.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.11.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.12.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.12.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.13.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.13.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.14.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.14.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.15.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.15.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.16.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.16.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.17.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.17.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.18.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.18.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.19.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.19.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.20.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.20.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.21.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.21.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.22.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.22.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.23.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.23.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.24.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.24.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.25.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.25.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.26.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.26.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.27.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.27.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.28.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.28.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.29.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.29.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.30.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.30.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([8, 4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 8]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.31.input_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.layers.31.post_attention_layernorm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.model.norm.weight, Shape: torch.Size([4096]), Requires grad: False\n",
            "Parameter name: peft_model.base_model.model.lm_head.weight, Shape: torch.Size([32000, 4096]), Requires grad: False\n",
            "Parameter name: classifier.weight, Shape: torch.Size([3, 4096]), Requires grad: True\n",
            "Parameter name: classifier.bias, Shape: torch.Size([3]), Requires grad: True\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter name: {name}, Shape: {param.shape}, Requires grad: {param.requires_grad}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJWrGVLtV6m-"
      },
      "source": [
        "1. 선형 분류기하나만 추가 및 분류기 외 그래디언트 false 후 학습 시모델이 너무 단조로워, 학습 로스가 0으로 학습이 안됨  \n",
        "2. 시퀀셜 레이어를 추가하거나 헤드(채널)를 추가 하는 등의 작업이 필요해보여 프리징은 제외  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwFPeafxH1Jl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "  acc=accuracy_score(labels , preds)\n",
        "  return {\"accuracy\":acc, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ863l2a8dO4"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, max_length = max_len,\n",
        "                                                   padding='max_length',return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_7wPHPLmJEX"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# 훈련 인수 설정\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"dongseon/kaggle_mistral-clf\",\n",
        "    max_step = 30,\n",
        "    # num_train_epochs=1,\n",
        "    per_device_train_batch_size=12,\n",
        "    per_device_eval_batch_size=12,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    optim=\"adamw_hf\",\n",
        "    learning_rate=2e-5,\n",
        "    push_to_hub=True,\n",
        "    save_safetensors= False,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "# Trainer 생성\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    # data_collator = data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "H4niobz9sHYQ",
        "outputId": "05ee59ac-a89a-4c06-f516-0e56d4383dc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='3830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  11/3830 00:31 < 3:39:44, 0.29 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='958' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/958 05:41 < 48:48, 0.29 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1848\u001b[0m                 \u001b[0;31m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m                 return inner_training_loop(\n\u001b[0m\u001b[1;32m   1851\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m                     \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2278\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2279\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2660\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2662\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2663\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3467\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   3468\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3469\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3649\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3650\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3651\u001b[0m             \u001b[0mmain_input_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"main_input_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3652\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_input_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3834\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mloss_without_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3835\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3836\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3837\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3160\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3161\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3162\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-b17f5e035a3b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeft_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 return self.base_model(\n\u001b[0m\u001b[1;32m   1431\u001b[0m                     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1159\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                 )\n\u001b[1;32m   1042\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1044\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    758\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/gptq.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# note: logic differs from default Linear because merging is not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_linear_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_adapters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/qlinear/qlinear_cuda_old.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscales\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         out = out.to(dtype=x_dtype).reshape(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdgE6TpSO124"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub(\n",
        "    \"dongseon/kaggle_mistral-clf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp6TWweQa6rv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# GPU 메모리 비우기\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCwC51JR7da"
      },
      "source": [
        "## low training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQuxX24qGePe"
      },
      "outputs": [],
      "source": [
        "# device = \"cuda\"\n",
        "# LEARNING_RATE = 1e-5\n",
        "# best_model_path = \"/content/best_model.pt\"\n",
        "# checkpoint_path = \"/content\"\n",
        "# EPOCHS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KR0gaP-GeUC"
      },
      "outputs": [],
      "source": [
        "# import torch.optim as optim\n",
        "# from torch.cuda.amp import GradScaler, autocast\n",
        "# # Optimizer 설정\n",
        "# optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
        "# # AMP를 위한 GradScaler 설정\n",
        "# scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mOxz11FGeYi"
      },
      "outputs": [],
      "source": [
        "# def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "#     checkpoint = torch.load(checkpoint_fpath)\n",
        "#     model.load_state_dict(checkpoint['state_dict'])\n",
        "#     optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "#     valid_loss_min = checkpoint['valid_loss_min']\n",
        "#     return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n",
        "\n",
        "# def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "#     f_path = checkpoint_path\n",
        "#     torch.save(state, f_path)\n",
        "#     if is_best:\n",
        "#         best_fpath = best_model_path\n",
        "#         shutil.copyfile(f_path, best_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tdMSqTCGD3l"
      },
      "outputs": [],
      "source": [
        "# def train_model(n_epochs, training_loader, validation_loader,model,\n",
        "#                 optimizer,checkpoint_path,  best_model_path):\n",
        "\n",
        "#   for epoch in range(1, n_epochs+1):\n",
        "#     train_loss = 0\n",
        "#     valid_loss = 0\n",
        "\n",
        "#     model.train()\n",
        "#     print('############# Epoch {}: Training Start   #############'.format(epoch))\n",
        "#     for batch_idx, data in enumerate(training_loader):\n",
        "\n",
        "#         input_ids = data['input_ids'].to(device)\n",
        "#         attention_mask = data['attention_mask'].to(device)\n",
        "#         labels = data['labels'].to(device)\n",
        "\n",
        "#         loss, _ = model(input_ids, attention_mask, labels)\n",
        "#         optimizer.zero_grad()\n",
        "#         # Loss 역전파\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         train_loss += loss.item()\n",
        "\n",
        "#     print('############# Epoch {}: Training End     #############'.format(epoch))\n",
        "\n",
        "\n",
        "#     print('############# Epoch {}: Validation Start   #############'.format(epoch))\n",
        "#     model.eval()\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#       for batch_idx, data in enumerate(validation_loader):\n",
        "\n",
        "#         input_ids = data['input_ids'].to(device)\n",
        "#         attention_mask = data['attention_mask'].to(device)\n",
        "#         labels = data['labels'].to(device)\n",
        "\n",
        "#         loss, _ = model(input_ids, attention_mask, labels)\n",
        "\n",
        "#         valid_loss += loss.item()\n",
        "#     print('############# Epoch {}: Validation End     #############'.format(epoch))\n",
        "\n",
        "#     train_loss = train_loss / len(training_loader)\n",
        "#     valid_loss = valid_loss / len(validation_loader)\n",
        "\n",
        "#     print('Epoch: {} \\tAverage Training Loss: {:.6f}'.format(epoch, train_loss))\n",
        "#     print('Epoch: {} \\tAverage Validation Loss: {:.6f}'.format(epoch, valid_loss))\n",
        "\n",
        "\n",
        "#     checkpoint = {\n",
        "#           'epoch': epoch + 1,\n",
        "#           'valid_loss_min': valid_loss,\n",
        "#           'state_dict': model.state_dict(),\n",
        "#           'optimizer': optimizer.state_dict()\n",
        "#     }\n",
        "\n",
        "#       # save checkpoint\n",
        "#     save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "#     new_state_dict = {key: value for key, value in model.state_dict().items()}    # if key != 'linear.weight' and key != 'linear.bias'}\n",
        "#     torch.save(new_state_dict, '/content/drive/MyDrive/best_model_weights.pt')\n",
        "#     ## TODO: save the model if validation loss has decreased\n",
        "#     if valid_loss <= valid_loss_min:\n",
        "#       print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "#       # save checkpoint as best model\n",
        "#       save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "#       torch.save(new_state_dict, '/content/best_model_weights.pt')\n",
        "#       valid_loss_min = valid_loss\n",
        "\n",
        "#     print('############# Epoch {}  Done   #############\\n'.format(epoch))\n",
        "\n",
        "#   return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln8w6xTNGD89"
      },
      "outputs": [],
      "source": [
        "# trained_model = train_model(EPOCHS, train_data_loader, valid_data_loader model, optimizer,checkpoint_path, best_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VwsUZmlGEF2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwpASZ7E59Ka"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9c5HeobjDo6"
      },
      "outputs": [],
      "source": [
        "inputs = next(iter(train_data_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKsew1B808MX",
        "outputId": "d4681795-5ee9-4108-e797-2976e451ad3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 512])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs['input_ids'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4sjlVtM7xNU"
      },
      "outputs": [],
      "source": [
        "outputs = peft_model(inputs['input_ids'].to(\"cuda\"), attention_mask=inputs['attention_mask'].to(\"cuda\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSLuJI0b_YgE",
        "outputId": "f6a8184e-8997-4260-ed69-9d512ae8a338"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 512, 4096])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs.hidden_states[-1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qLyHHQy8A9p",
        "outputId": "c701686d-403f-49f7-b39d-6fb5f13ef990"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 4096])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs.hidden_states[-1].mean(dim=1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afAdGyRE73ZM"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "classifier = nn.Linear(4096, 3 , device = \"cuda\")\n",
        "classifier.weight.data = classifier.weight.data.to(torch.float16)\n",
        "classifier.bias.data = classifier.bias.data.to(torch.float16)\n",
        "\n",
        "hidden_states = outputs.hidden_states[-1]\n",
        "pooled_output = hidden_states.mean(dim=1)  # 평균 풀링\n",
        "\n",
        "# pooled_output = pooled_output.to(torch.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCdHu2HH_u6U",
        "outputId": "717f3836-7d14-4c75-a207-99bfdffd6b0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pooled_output.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDFUAEyB4P1z",
        "outputId": "31f20093-ef0b-468b-e553-2a97842cd309"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 3])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits = classifier(pooled_output)\n",
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZccoXjkANjg1",
        "outputId": "e42fcb0a-e5fc-4cf5-c338-c19e77f5865b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = inputs['labels'].to(\"cuda\")\n",
        "labels.squeeze().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9fzKVtCNu5w",
        "outputId": "485435b2-3ad9-455d-917b-23083fe2500a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0], device='cuda:0')"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eDEhw_-KWcL"
      },
      "outputs": [],
      "source": [
        "loss = loss_fn(logits, labels.squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOx2UWKhOac7",
        "outputId": "ed652e6a-08d3-4b98-ce41-99b121ec6151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.8740, device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSuZsS4W9clW"
      },
      "outputs": [],
      "source": [
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "SLV_Y16-zqip",
        "outputId": "d2d513e7-3ddc-4c83-8a9c-7c2d850c2664"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 39.56 GiB total capacity; 34.21 GiB already allocated; 348.81 MiB free; 38.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-65e320002ddd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-86eadbe4248d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeft_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 return self.base_model(\n\u001b[0m\u001b[1;32m   1431\u001b[0m                     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1159\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                 )\n\u001b[1;32m   1042\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1044\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    758\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# upcast attention to fp32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1845\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 39.56 GiB total capacity; 34.21 GiB already allocated; 348.81 MiB free; 38.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "_, logit = model(inputs['input_ids'].to(\"cuda\"), attention_mask=inputs['attention_mask'].to(\"cuda\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI8kDXtmz3nb"
      },
      "outputs": [],
      "source": [
        "logit.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss419CMvMt0D"
      },
      "source": [
        "# Test Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "_sy7_MV4SPA7",
        "outputId": "0a2773cf-3ca1-455e-fab7-1da6ad133d2c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2a4dab328d84c87bf8f4d26c01cccfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "442ef05f63bc410e96694789137c28cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17015f1e278a4c3690cd6cc303449c8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5baf10d1e48444db8fc62baa848845a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b15c82be5304498ab58ced67aa47cbc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "model_name = \"dongseon/kaggle_mistral-clf\"\n",
        "\n",
        "# PEFT 모델에 분류기 추가\n",
        "# model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI6rbYqXIMXK",
        "outputId": "c3603d70-9762-4ac9-fcac-0c4888555981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dongseon  logs\tsample_submission.csv  test.csv  train.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-CJU_yCqIJDH",
        "outputId": "450fc30a-d70b-4fa0-ffe7-c1268efddd53"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.cache/huggingface/hub/models--dongseon--kaggle_mistral-clf/snapshots/89397e9505820aca04825aaae0aafa32401b46ee/pytorch_model.bin'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from huggingface_hub import hf_hub_download\n",
        "# hf_hub_download(repo_id=model_name, filename=\"pytorch_model.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhyBXllHH1UF"
      },
      "outputs": [],
      "source": [
        "model = PeftModelForClassification(peft_model, peft_model.config).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vrghz7MaLw_"
      },
      "outputs": [],
      "source": [
        "model_dict = torch.load('./dongseon/kaggle_mistral-clf/pytorch_model.bin', map_location=torch.device('cuda'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "hzT2IgxQHyx0",
        "outputId": "fecf8336-712f-4b30-94ab-37006a36ecf5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-489896b715c0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(model_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtZgsNaWVXAB",
        "outputId": "2d04f5ad-4327-4d63-cbb2-2e96e4be9731"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForClassification(\n",
              "  (peft_model): PeftModelForCausalLM(\n",
              "    (base_model): LoraModel(\n",
              "      (model): MistralForCausalLM(\n",
              "        (model): MistralModel(\n",
              "          (embed_tokens): Embedding(32000, 4096)\n",
              "          (layers): ModuleList(\n",
              "            (0-31): 32 x MistralDecoderLayer(\n",
              "              (self_attn): MistralAttention(\n",
              "                (rotary_emb): MistralRotaryEmbedding()\n",
              "                (k_proj): QuantLinear()\n",
              "                (o_proj): QuantLinear()\n",
              "                (q_proj): lora.QuantLinear(\n",
              "                  (base_layer): QuantLinear()\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (quant_linear_module): QuantLinear()\n",
              "                )\n",
              "                (v_proj): lora.QuantLinear(\n",
              "                  (base_layer): QuantLinear()\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (quant_linear_module): QuantLinear()\n",
              "                )\n",
              "              )\n",
              "              (mlp): MistralMLP(\n",
              "                (act_fn): SiLU()\n",
              "                (down_proj): QuantLinear()\n",
              "                (gate_proj): QuantLinear()\n",
              "                (up_proj): QuantLinear()\n",
              "              )\n",
              "              (input_layernorm): MistralRMSNorm()\n",
              "              (post_attention_layernorm): MistralRMSNorm()\n",
              "            )\n",
              "          )\n",
              "          (norm): MistralRMSNorm()\n",
              "        )\n",
              "        (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (classifier): Linear(in_features=4096, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39EOSnNAVI-2"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load(\"./pytorch_model.bin\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h0L6H9-RNmJ",
        "outputId": "9e5a9eb0-213e-4711-a7ec-757360f07163"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = pd.read_csv('test.csv')\n",
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aHIdpqBVZ6K"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "test[\"prompt\"] = test[\"prompt\"].apply(lambda x: json.loads(x)[0])\n",
        "test[\"response_a\"] = test[\"response_a\"].apply(lambda x: json.loads(x)[0])\n",
        "test[\"response_b\"] = test[\"response_b\"].apply(lambda x: json.loads(x)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVIxmDM5X-II"
      },
      "outputs": [],
      "source": [
        "test['new_text'] = [ \"### prompt: \"+test['prompt'][x]+\" ### response_a: \"+test['response_a'][x]+\" ### response_b: \"+test['response_b'][x] for x in range(len(test)) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "pOYfM58VYIX3",
        "outputId": "8bbe6354-e952-4f75-879a-b988976f5a89"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 613299,\n        \"min\": 136060,\n        \"max\": 1233961,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          136060,\n          211333,\n          1233961\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"I have three oranges today, I ate an orange yesterday. How many oranges do I have?\",\n          \"You are a mediator in a heated political debate between two opposing parties. Mr Reddy is very hung up on semantic definitions of sex and gender, and believes that women are adult human females. Meanwhile Ms Blue is extremely fluid with definitions and does not care about truth. He (Ms blue uses he/him pronouns) insists that anybody can be any gender, gametes don't mean anything, and that men can get pregnant. You, Mr Goddy are tasked with helping them both find a middle ground.\",\n          \"How to initialize the classification head when I do transfer learning. For example, I have a pre-trained vision transformer on ImageNet, and now I want to finetune it on StanfordCars\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"You have two oranges today.\",\n          \"Thank you for sharing the details of the situation. As a mediator, I understand the importance of finding a middle ground that both parties can agree upon.\\n\\nIt is important to recognize that language and definitions can be complex and can vary depending on cultural and societal norms. At the same time, it is also important to acknowledge the biological differences between males and females.\\n\\nOne possible approach to finding a middle ground could be to focus on respecting individuals' self-identification and autonomy while also acknowledging the biological differences between males and females. This could involve using inclusive language that reflects individuals' gender identities while also recognizing the importance of biological sex in certain contexts, such as medical treatment and reproductive health.\\n\\nIt may also be helpful to explore ways to create a more inclusive society where individuals of all gender identities are valued and respected. This could involve promoting education and awareness about gender diversity and creating policies and practices that support individuals' gender identities and expression.\\n\\nUltimately, the goal of mediation is to find a solution that meets the needs and concerns of both parties. By focusing on mutual respect, open communication, and a willingness to find common ground, it is possible to reach a resolution that allows both parties to move forward in a positive and productive way.\",\n          \"When you want to initialize the classification head for transfer learning, you can follow these steps:\\n\\n  1. Load the pre-trained model: First, load the pre-trained vision transformer model on ImageNet. You can use popular deep learning libraries like PyTorch or TensorFlow to load the model.\\n  2. Freeze the pre-trained layers: Next, you need to freeze the pre-trained layers of the model so that they don't get updated during the training process. This is because the pre-trained layers have learned useful features that can be reused for the new task.\\n  3. Add a new classification head: Now, you need to add a new classification head to the model. The classification head is responsible for outputting the predicted class for a given input image. The size of the classification head depends on the number of classes in the new task. For example, if you are working on the StanfordCars dataset, which has 196 classes, you would need a classification head with 196 output neurons.\\n  4. Initialize the classification head: Initialize the weights of the classification head randomly or using pre-trained weights. This is important because the initial weights can have a significant impact on the performance of the model.\\n  5. Train the model: Finally, you can train the model on the new task using your labeled data. During training, only the weights of the classification head will be updated, while the weights of the frozen pre-trained layers will remain unchanged. This allows the model to learn task-specific features while leveraging the pre-trained features.\\n\\nNote that there are different ways to initialize the classification head, such as using Xavier initialization, Kaiming initialization, or He initialization. You can choose the initialization method that works best for your specific task and model architecture.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.\",\n          \"Mr Reddy and Ms Blue both have valid points in their arguments. On one hand, Mr Reddy is correct that women are adult human females, as defined by their biological and physical characteristics. However, Ms Blue is right that gender is a more fluid concept and that people can identify with any gender they choose. A compromise could be that gender is defined by an individual's self-identification, while sex is defined by their biological characteristics.\",\n          \"To initialize the classification head when performing transfer learning, follow these steps:\\n\\n1. Load the pre-trained vision transformer model that was trained on ImageNet.\\n2. Replace the existing classification head with a new one suitable for the StanfordCars dataset.\\n3. Initialize the weights of the new classification head with random values or pre-trained weights if available.\\n4. Freeze the weights of the vision transformer backbone to prevent them from being updated during training.\\n5. Train the model on the StanfordCars dataset, fine-tuning the classification head while keeping the backbone frozen.\\n\\nHere's an example implementation in Python using PyTorch:\\n\\n```python\\nimport torch\\nimport torch.nn as nn\\nimport torchvision.models as models\\n\\n# Step 1: Load pre-trained vision transformer model\\nvision_transformer = models.vit_base_patch16_224(pretrained=True)\\n\\n# Step 2: Replace classification head\\nnum_classes = 196  # Number of classes in StanfordCars dataset\\nvision_transformer.head = nn.Linear(vision_transformer.head.in_features, num_classes)\\n\\n# Step 3: Initialize weights of new classification head\\nnn.init.xavier_uniform_(vision_transformer.head.weight)\\nnn.init.constant_(vision_transformer.head.bias, 0)\\n\\n# Step 4: Freeze the weights of the backbone\\nfor param in vision_transformer.parameters():\\n    param.requires_grad = False\\n\\n# Step 5: Train the model on StanfordCars dataset\\n# ...\\n```\\n\\nIn this example, we load the pre-trained vision transformer model using `torchvision.models.vit_base_patch16_224`. We then replace the `head` (classification head) of the model with a new linear layer (`nn.Linear`) that has the appropriate number of output classes for the StanfordCars dataset.\\n\\nAfter replacing the classification head, we initialize its weights using Xavier initialization (`nn.init.xavier_uniform_`) and set its biases to zero (`nn.init.constant_`).\\n\\nFinally, we freeze the weights of the vision transformer backbone by setting `requires_grad=False` for all parameters. This ensures that only the weights of the classification head will be updated during training on the StanfordCars dataset.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"### prompt: I have three oranges today, I ate an orange yesterday. How many oranges do I have? ### response_a: You have two oranges today. ### response_b: You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.\",\n          \"### prompt: You are a mediator in a heated political debate between two opposing parties. Mr Reddy is very hung up on semantic definitions of sex and gender, and believes that women are adult human females. Meanwhile Ms Blue is extremely fluid with definitions and does not care about truth. He (Ms blue uses he/him pronouns) insists that anybody can be any gender, gametes don't mean anything, and that men can get pregnant. You, Mr Goddy are tasked with helping them both find a middle ground. ### response_a: Thank you for sharing the details of the situation. As a mediator, I understand the importance of finding a middle ground that both parties can agree upon.\\n\\nIt is important to recognize that language and definitions can be complex and can vary depending on cultural and societal norms. At the same time, it is also important to acknowledge the biological differences between males and females.\\n\\nOne possible approach to finding a middle ground could be to focus on respecting individuals' self-identification and autonomy while also acknowledging the biological differences between males and females. This could involve using inclusive language that reflects individuals' gender identities while also recognizing the importance of biological sex in certain contexts, such as medical treatment and reproductive health.\\n\\nIt may also be helpful to explore ways to create a more inclusive society where individuals of all gender identities are valued and respected. This could involve promoting education and awareness about gender diversity and creating policies and practices that support individuals' gender identities and expression.\\n\\nUltimately, the goal of mediation is to find a solution that meets the needs and concerns of both parties. By focusing on mutual respect, open communication, and a willingness to find common ground, it is possible to reach a resolution that allows both parties to move forward in a positive and productive way. ### response_b: Mr Reddy and Ms Blue both have valid points in their arguments. On one hand, Mr Reddy is correct that women are adult human females, as defined by their biological and physical characteristics. However, Ms Blue is right that gender is a more fluid concept and that people can identify with any gender they choose. A compromise could be that gender is defined by an individual's self-identification, while sex is defined by their biological characteristics.\",\n          \"### prompt: How to initialize the classification head when I do transfer learning. For example, I have a pre-trained vision transformer on ImageNet, and now I want to finetune it on StanfordCars ### response_a: When you want to initialize the classification head for transfer learning, you can follow these steps:\\n\\n  1. Load the pre-trained model: First, load the pre-trained vision transformer model on ImageNet. You can use popular deep learning libraries like PyTorch or TensorFlow to load the model.\\n  2. Freeze the pre-trained layers: Next, you need to freeze the pre-trained layers of the model so that they don't get updated during the training process. This is because the pre-trained layers have learned useful features that can be reused for the new task.\\n  3. Add a new classification head: Now, you need to add a new classification head to the model. The classification head is responsible for outputting the predicted class for a given input image. The size of the classification head depends on the number of classes in the new task. For example, if you are working on the StanfordCars dataset, which has 196 classes, you would need a classification head with 196 output neurons.\\n  4. Initialize the classification head: Initialize the weights of the classification head randomly or using pre-trained weights. This is important because the initial weights can have a significant impact on the performance of the model.\\n  5. Train the model: Finally, you can train the model on the new task using your labeled data. During training, only the weights of the classification head will be updated, while the weights of the frozen pre-trained layers will remain unchanged. This allows the model to learn task-specific features while leveraging the pre-trained features.\\n\\nNote that there are different ways to initialize the classification head, such as using Xavier initialization, Kaiming initialization, or He initialization. You can choose the initialization method that works best for your specific task and model architecture. ### response_b: To initialize the classification head when performing transfer learning, follow these steps:\\n\\n1. Load the pre-trained vision transformer model that was trained on ImageNet.\\n2. Replace the existing classification head with a new one suitable for the StanfordCars dataset.\\n3. Initialize the weights of the new classification head with random values or pre-trained weights if available.\\n4. Freeze the weights of the vision transformer backbone to prevent them from being updated during training.\\n5. Train the model on the StanfordCars dataset, fine-tuning the classification head while keeping the backbone frozen.\\n\\nHere's an example implementation in Python using PyTorch:\\n\\n```python\\nimport torch\\nimport torch.nn as nn\\nimport torchvision.models as models\\n\\n# Step 1: Load pre-trained vision transformer model\\nvision_transformer = models.vit_base_patch16_224(pretrained=True)\\n\\n# Step 2: Replace classification head\\nnum_classes = 196  # Number of classes in StanfordCars dataset\\nvision_transformer.head = nn.Linear(vision_transformer.head.in_features, num_classes)\\n\\n# Step 3: Initialize weights of new classification head\\nnn.init.xavier_uniform_(vision_transformer.head.weight)\\nnn.init.constant_(vision_transformer.head.bias, 0)\\n\\n# Step 4: Freeze the weights of the backbone\\nfor param in vision_transformer.parameters():\\n    param.requires_grad = False\\n\\n# Step 5: Train the model on StanfordCars dataset\\n# ...\\n```\\n\\nIn this example, we load the pre-trained vision transformer model using `torchvision.models.vit_base_patch16_224`. We then replace the `head` (classification head) of the model with a new linear layer (`nn.Linear`) that has the appropriate number of output classes for the StanfordCars dataset.\\n\\nAfter replacing the classification head, we initialize its weights using Xavier initialization (`nn.init.xavier_uniform_`) and set its biases to zero (`nn.init.constant_`).\\n\\nFinally, we freeze the weights of the vision transformer backbone by setting `requires_grad=False` for all parameters. This ensures that only the weights of the classification head will be updated during training on the StanfordCars dataset.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a0d23c4b-d02f-41d7-a305-d673e3696d32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>new_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>136060</td>\n",
              "      <td>I have three oranges today, I ate an orange ye...</td>\n",
              "      <td>You have two oranges today.</td>\n",
              "      <td>You still have three oranges. Eating an orange...</td>\n",
              "      <td>### prompt: I have three oranges today, I ate ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>211333</td>\n",
              "      <td>You are a mediator in a heated political debat...</td>\n",
              "      <td>Thank you for sharing the details of the situa...</td>\n",
              "      <td>Mr Reddy and Ms Blue both have valid points in...</td>\n",
              "      <td>### prompt: You are a mediator in a heated pol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1233961</td>\n",
              "      <td>How to initialize the classification head when...</td>\n",
              "      <td>When you want to initialize the classification...</td>\n",
              "      <td>To initialize the classification head when per...</td>\n",
              "      <td>### prompt: How to initialize the classificati...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0d23c4b-d02f-41d7-a305-d673e3696d32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0d23c4b-d02f-41d7-a305-d673e3696d32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0d23c4b-d02f-41d7-a305-d673e3696d32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4d82915c-d827-4e83-a1ea-f755a4d5c068\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d82915c-d827-4e83-a1ea-f755a4d5c068')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4d82915c-d827-4e83-a1ea-f755a4d5c068 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        id                                             prompt  \\\n",
              "0   136060  I have three oranges today, I ate an orange ye...   \n",
              "1   211333  You are a mediator in a heated political debat...   \n",
              "2  1233961  How to initialize the classification head when...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0                        You have two oranges today.   \n",
              "1  Thank you for sharing the details of the situa...   \n",
              "2  When you want to initialize the classification...   \n",
              "\n",
              "                                          response_b  \\\n",
              "0  You still have three oranges. Eating an orange...   \n",
              "1  Mr Reddy and Ms Blue both have valid points in...   \n",
              "2  To initialize the classification head when per...   \n",
              "\n",
              "                                            new_text  \n",
              "0  ### prompt: I have three oranges today, I ate ...  \n",
              "1  ### prompt: You are a mediator in a heated pol...  \n",
              "2  ### prompt: How to initialize the classificati...  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eO2cKEGrQZkX"
      },
      "outputs": [],
      "source": [
        "test_df = test.copy()\n",
        "\n",
        "def tokenize_prompt(prompt, chosen, rejected):\n",
        "    prompt_tokens = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length = 4096)\n",
        "    chosen_tokens = tokenizer(chosen, return_tensors=\"pt\", truncation=True, padding=True, max_length = 4096)\n",
        "    rejected_tokens = tokenizer(rejected, return_tensors=\"pt\", truncation=True, padding=True, max_length = 4096)\n",
        "\n",
        "    return prompt_tokens['input_ids'], chosen_tokens['input_ids'], rejected_tokens['input_ids']\n",
        "\n",
        "p_list = []\n",
        "c_list = []\n",
        "r_list = []\n",
        "\n",
        "for i in range(len(test_df)):\n",
        "  prompt_tokens, chosen_tokens, rejected_tokens = tokenize_prompt(test_df[\"prompt\"].iloc[i], test_df[\"response_a\"].iloc[i], test_df[\"response_b\"].iloc[i])\n",
        "  p_list.append(len(prompt_tokens[0]))\n",
        "  c_list.append(len(chosen_tokens[0]))\n",
        "  r_list.append(len(rejected_tokens[0]))\n",
        "\n",
        "test_df['p_len'] = p_list\n",
        "test_df['c_len'] = c_list\n",
        "test_df['r_len'] = r_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhloP1VeQ1Ko",
        "outputId": "4c2e14e9-d286-49b2-c7a9-415fe78fd163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110 \n",
            " 383 \n",
            " 546\n",
            "58.0 \n",
            " 220.33333333333334 \n",
            " 220.66666666666666\n"
          ]
        }
      ],
      "source": [
        "print(np.max(test_df['p_len']),\"\\n\",np.max(test_df['c_len']),\"\\n\",np.max(test_df['r_len']))\n",
        "print(np.mean(test_df['p_len']),\"\\n\",np.mean(test_df['c_len']),\"\\n\",np.mean(test_df['r_len']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4ohrmDmYIVf"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomDataset2(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.title = df['new_text']\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.title)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        title = str(self.title[index])\n",
        "        title = \" \".join(title.split())\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            title,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten()\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmbIZ82uYqiA"
      },
      "outputs": [],
      "source": [
        "test_dataset = CustomDataset2(test, tokenizer, max_len)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ3pjYdnTTQ0",
        "outputId": "32a0d4a9-ecad-4174-94b2-a855afaeae8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset.__len__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vgk18pahLPCw"
      },
      "outputs": [],
      "source": [
        "test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMxmvthqYw6H",
        "outputId": "1b5225b1-7c6d-46a5-8cef-8190b7aa46a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    1,   774, 11510,  ...,     2,     2,     2]),\n",
              " 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0])}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2WabOCqLYWQ",
        "outputId": "e98ec12c-5953-495f-c396-28c777c6cae0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    1,   774, 11510,  ...,     2,     2,     2],\n",
              "         [    1,   774, 11510,  ...,     2,     2,     2],\n",
              "         [    1,   774, 11510,  ...,     2,     2,     2]]),\n",
              " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]])}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aaa = next(iter(test_data_loader))\n",
        "aaa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyEtaJziLg73"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "with torch.no_grad():\n",
        "  input_ids = aaa['input_ids'].to(device, dtype = torch.long)\n",
        "  attention_mask = aaa['attention_mask'].to(device, dtype = torch.long)\n",
        "  _, logits = model(input_ids, attention_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6oZMLJpL4co",
        "outputId": "5ca1674b-1b2d-45fe-edd2-7a4f7c43cb9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.2158, -0.6289, -2.8066],\n",
              "        [ 1.3594, -4.3008, -5.8672],\n",
              "        [-0.4314, -1.4043, -3.4805]], device='cuda:0', dtype=torch.float16)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQw6_zRQYyXw"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\"\n",
        "\n",
        "target_list = []\n",
        "\n",
        "for data in test_data_loader:\n",
        "  with torch.no_grad():\n",
        "    input_ids = data['input_ids'].to(device, dtype = torch.long)\n",
        "    attention_mask = data['attention_mask'].to(device, dtype = torch.long)\n",
        "    _, logits = model(input_ids, attention_mask)\n",
        "    softmax_logits = torch.nn.functional.softmax(logits, dim=1)\n",
        "    target_list.append(softmax_logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNW52x40TAzi",
        "outputId": "8649a638-30c7-47fd-8ec1-ba5d2259a354"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.9956, 0.7017, 0.8506], dtype=float16)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_list[0].cpu().detach().numpy()[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6_O7IyITCz_"
      },
      "outputs": [],
      "source": [
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub['winner_model_a'] = target_list[0].cpu().detach().numpy()[:,0]\n",
        "sub['winner_model_b'] = target_list[0].cpu().detach().numpy()[:,1]\n",
        "sub['winner_tie'] = target_list[0].cpu().detach().numpy()[:,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLl_VzvgUfuJ"
      },
      "outputs": [],
      "source": [
        "sub.to_csv('submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBT4CySDVZjx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "naF3I9rUw_r8",
        "PdntNstHBOu3",
        "xX4P2Zh-8Y-Z",
        "SwpASZ7E59Ka",
        "Ss419CMvMt0D"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 8346466,
          "sourceId": 66631,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30698,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "006fe2a82244405ab22436287120edcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03acf0e3c5de4e498ccfdb6b24e22b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91592c793664b01b5d56bf250da2bc1",
            "placeholder": "​",
            "style": "IPY_MODEL_ba0253ece6bd4b3aa7bf2b6757091134",
            "value": " 51.0/51.0 [00:00&lt;00:00, 4.15kB/s]"
          }
        },
        "04aded80a5774429b982c87e93d2b4de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59a02a6927114fb99b6b532a5bf30d55",
            "placeholder": "​",
            "style": "IPY_MODEL_c72e844242bc44e6a9a4bc403164b3d7",
            "value": " 493k/493k [00:00&lt;00:00, 14.5MB/s]"
          }
        },
        "05b62a95c4da482c8b5a903120685c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "079f753989054a85ad03aba375a15441": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5525077b164f2a95efb353b829d927": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91f6ce8e67964ec0b99c5b075e49cfd6",
              "IPY_MODEL_d960a1ea14674c90b95c39b2b55c1aa7",
              "IPY_MODEL_db7230f0d64c4b5b8771abdc46919da4"
            ],
            "layout": "IPY_MODEL_0aa9411ea14747d99504fc6336f512f3"
          }
        },
        "0aa9411ea14747d99504fc6336f512f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d4bda61d3d04a349781ab2d2bf0d5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd6dc9e4488348058069956aa6e7bf72",
            "placeholder": "​",
            "style": "IPY_MODEL_a7788d690c9d45698f1f40a78716ca0c",
            "value": " 1.26k/1.26k [00:00&lt;00:00, 115kB/s]"
          }
        },
        "0df380689e8048a494c7dbfb9776b446": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c09d8bd43cbe481cae460719a75f341e",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e196ce15d6c94736a9856699e431b944",
            "value": 111
          }
        },
        "104ef6e8c2cf4ce698a061847b2593d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "108011e9fdb3423d805c4478687cdf62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a046ac18614a86894f31469592debb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e15cf352a725415f83bf4a81d4b2091d",
            "placeholder": "​",
            "style": "IPY_MODEL_30e27f725915429f8772c879729d8172",
            "value": " 7938/7938 [00:23&lt;00:00, 364.96 examples/s]"
          }
        },
        "1286a53735574ca5b22451856e9ce66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0101556661f42b5a391ec6a4684af6f",
            "placeholder": "​",
            "style": "IPY_MODEL_746efe9dfbbc4e198685b87ca6554ca8",
            "value": "Map: 100%"
          }
        },
        "13d6f37fb15342fa9a71aef90c476620": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16affd2ba0754498967f376cb693cade": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "181fd9d4d28c4cecba7e685b69fe9a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5975f80cfa3645528a0fd4b3f579631d",
              "IPY_MODEL_48942655d62349abae6e8331c89d6277",
              "IPY_MODEL_0d4bda61d3d04a349781ab2d2bf0d5bb"
            ],
            "layout": "IPY_MODEL_afd7ee119fb445d286625f49ea8ae268"
          }
        },
        "18a9084c930942dfa0e5ca97413d2516": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a3ab22097134b01b253e19edd77b51d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a77a932eec64199b16cc49ea317130e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29135b7aa4b942189ad21c39b0020d75",
              "IPY_MODEL_5330359946194b94862742cb1a164737",
              "IPY_MODEL_8841c914e02f4425af085379179d5015"
            ],
            "layout": "IPY_MODEL_6bafca1fa3f54475a0ee55a09e2c2a1d"
          }
        },
        "1b866ed2b0544c069fdc0922d7f74fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_983258e7f35e4167bbf204c9cfbef6bc",
            "placeholder": "​",
            "style": "IPY_MODEL_432ac55fb13849858476fd7142637efc",
            "value": " 111/111 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "1f4023cd87d14cbd92e97283616fb472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21f1462768944694bc3717c7763579c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcaea40435e5405b878c32d8bf703958",
              "IPY_MODEL_70165e2d36eb41528777744d620ee131",
              "IPY_MODEL_04aded80a5774429b982c87e93d2b4de"
            ],
            "layout": "IPY_MODEL_dbb0088887664a5d84cc17a78bce2237"
          }
        },
        "22a2774bfb4e4667acc353fbba392d10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "251e6f6aa144404bbbe8782a15d6dc64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac5bc036e2504f5b9ca48539fefc99e5",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05b62a95c4da482c8b5a903120685c08",
            "value": 1795303
          }
        },
        "2752561a16c6413c9be9fb41ec7b4669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dcf9c370d32403e890c8bfec439ea01",
            "max": 1460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a7bb724379e4fe8b1de60ef79ce160a",
            "value": 1460
          }
        },
        "28f2d0ddaae54e44899b54cd75aed050": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efd3813f39a74346ab411f73b678a057",
              "IPY_MODEL_e3739cfbe01e49a99fa5c91ae3b85c21",
              "IPY_MODEL_fde02c422e3c45498d2a03ede78f68ed"
            ],
            "layout": "IPY_MODEL_a352253498d944019ee674691927537b"
          }
        },
        "29135b7aa4b942189ad21c39b0020d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf98a7ade2584433806c0879416807a5",
            "placeholder": "​",
            "style": "IPY_MODEL_e831330e459d42a39a5f6f70d4d0f060",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "2b69fd9483714dc3b7d079ca73c49b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5991a7c8ee20459984d5a85b5c0e52f2",
              "IPY_MODEL_37a80c70ec744cbd9139cdd070168e4f",
              "IPY_MODEL_4920f05a25d641208ab4801fda1a33aa"
            ],
            "layout": "IPY_MODEL_fad53ea590bb49d8808d1c33e1f68f2b"
          }
        },
        "2cb00b99bf5c48db9259bfb8556b2ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dc6842683d04de9b67e5db139eecba3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2edd27009fd64446bad5efb9ce2394d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_108011e9fdb3423d805c4478687cdf62",
            "placeholder": "​",
            "style": "IPY_MODEL_e3e4ea448b70487d95c7157e50dbfd83",
            "value": " 1.46k/1.46k [00:00&lt;00:00, 127kB/s]"
          }
        },
        "30e27f725915429f8772c879729d8172": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "316bb133bc804887af8ec5aa4790218f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "328bb007f2ca45b9aab116dfecfa4aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_343029f37d804ead8af836d46c3fb98f",
            "max": 51,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42d2a594944847f2aa75d7469091d8db",
            "value": 51
          }
        },
        "336f2136b2b84bffb5b8814485122f38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33782af3ee0d49a79097f07cbf3ba005": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "343029f37d804ead8af836d46c3fb98f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364ae175855c4992813a30cc9864b810": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93fda078803d446494a3d38d47ce86f5",
            "max": 7938,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d2939a5c15542ccba9bf90c8ce8a6e5",
            "value": 7938
          }
        },
        "37a80c70ec744cbd9139cdd070168e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13d6f37fb15342fa9a71aef90c476620",
            "max": 31753,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18a9084c930942dfa0e5ca97413d2516",
            "value": 31753
          }
        },
        "3822e0b21d1948f4bfe3c505f82677b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38f05d147c59436ca91c0462cbfab56d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dcf9c370d32403e890c8bfec439ea01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e21bc30b09045208354f992a3c875d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3c51625c9a641f7a66c0b146acdd441",
              "IPY_MODEL_8f55ee660b6e47288225bab274ddb856",
              "IPY_MODEL_82df653994bd48e28ad8d508c752fcf9"
            ],
            "layout": "IPY_MODEL_a0d30a714a214ecbae30ae97dc57f1df"
          }
        },
        "3e5fb58c31114bcabe1b7c97af192964": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92b131f472f9477d8839c354bb03cc78",
              "IPY_MODEL_b2f3974cdc69446fae8deff40af448fc",
              "IPY_MODEL_de920037a30f45568b1bdee400752ae8"
            ],
            "layout": "IPY_MODEL_431cd7ed6b81468b9e403584e58e17d1"
          }
        },
        "41964f83005445eab064da2788ab8948": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d2a594944847f2aa75d7469091d8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "431cd7ed6b81468b9e403584e58e17d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "432ac55fb13849858476fd7142637efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "433205a50bf349bab53f939d3f465c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a340be79b62347b38bf6ce12586b96f0",
            "placeholder": "​",
            "style": "IPY_MODEL_96a6151b07ef470e9be1e5dfd45f8566",
            "value": "tokenizer.json: 100%"
          }
        },
        "44736b08e38443b28cdab42589cdbe9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_639e04cb241b4504858b1631c379f530",
              "IPY_MODEL_251e6f6aa144404bbbe8782a15d6dc64",
              "IPY_MODEL_f492126461f04498b0c5e8640b2dcabc"
            ],
            "layout": "IPY_MODEL_a71f067cdb2e40cba3a29b1b30617e71"
          }
        },
        "45f1b83380464363afb134331ce4cc55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47d4c5607c75407db7572411d1536418": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48942655d62349abae6e8331c89d6277": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d68963bbe9ec4586ab7fed453b001290",
            "max": 1258,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df95676707254ec8b765db7dea9293a2",
            "value": 1258
          }
        },
        "4920f05a25d641208ab4801fda1a33aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_909c654f2bfe4da7b26f52e720130a48",
            "placeholder": "​",
            "style": "IPY_MODEL_faf0e262de994137bee8d455bdbdbc11",
            "value": " 31753/31753 [01:33&lt;00:00, 356.39 examples/s]"
          }
        },
        "4a003abec19447b3b183a4d1d1908825": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a08ff8bf52c485d92a0176c35401260": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4defa628ed864b02826ed73520850c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8448a26edbc462483e23758d6f3ac91",
            "max": 13648432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cb00b99bf5c48db9259bfb8556b2ff3",
            "value": 13648432
          }
        },
        "504e1f617ed14dfcad816d425c95044a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5103eebc511d488db991271aba37c824": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518fe28eaf14419082ca5cd16ec3c7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5330359946194b94862742cb1a164737": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c9cd78319f48f183058decb7f0d8d9",
            "max": 437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ac50861f97749eeb3a13c7eaa44d63e",
            "value": 437
          }
        },
        "5394e21a6d6e41af84e9d1aec7dff201": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5479cd9f848e40e59bf3aebffc548e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a72b372c850641d9aad30ce8a784b81a",
            "max": 1462,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ded652f6b194d6db9c223671edda9df",
            "value": 1462
          }
        },
        "5489d57115254e6db8f781f26252e0ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "566dd04bce824f51bbfbacbfb230b1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5975f80cfa3645528a0fd4b3f579631d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a30f6291eec84eb6b66e2d7a201fefd4",
            "placeholder": "​",
            "style": "IPY_MODEL_7ae6ac4fcfc5408aa42ce9faed94a1ff",
            "value": "config.json: 100%"
          }
        },
        "5991a7c8ee20459984d5a85b5c0e52f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a0f69f43b841d993383e2026017e5e",
            "placeholder": "​",
            "style": "IPY_MODEL_f9a150b9074c45629a730b5834925089",
            "value": "Map: 100%"
          }
        },
        "59a02a6927114fb99b6b532a5bf30d55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c7b9477caa54bfd9680ddeaf279f694": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72b30d5d6eec40f396c7cc47f63b99bf",
              "IPY_MODEL_0df380689e8048a494c7dbfb9776b446",
              "IPY_MODEL_1b866ed2b0544c069fdc0922d7f74fe3"
            ],
            "layout": "IPY_MODEL_f3cdbc823928401f9673c8f7b6742fab"
          }
        },
        "5e23d8efd05c44698b454187584ba95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ec9ff2929ee47fb9ec1ac3aec6effed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef2f607cbfdb40a9b87745ac2d9046c3",
            "placeholder": "​",
            "style": "IPY_MODEL_a6bfa24be9d0435f82603343ab530bcc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "63796cb8612a471f889801d46f2f2ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_658ba88f373246fb910651ec090ba222",
              "IPY_MODEL_4defa628ed864b02826ed73520850c3b",
              "IPY_MODEL_886eedbb79784b7ea5419bcc48611859"
            ],
            "layout": "IPY_MODEL_72407fd5546847b98a7d605fbefe9db5"
          }
        },
        "639e04cb241b4504858b1631c379f530": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_316bb133bc804887af8ec5aa4790218f",
            "placeholder": "​",
            "style": "IPY_MODEL_5e23d8efd05c44698b454187584ba95c",
            "value": "tokenizer.json: 100%"
          }
        },
        "6497b669aba14eb7b16e0ddabc193dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f05d147c59436ca91c0462cbfab56d",
            "placeholder": "​",
            "style": "IPY_MODEL_33782af3ee0d49a79097f07cbf3ba005",
            "value": " 4.16G/4.16G [00:18&lt;00:00, 303MB/s]"
          }
        },
        "658ba88f373246fb910651ec090ba222": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_336f2136b2b84bffb5b8814485122f38",
            "placeholder": "​",
            "style": "IPY_MODEL_566dd04bce824f51bbfbacbfb230b1da",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "67084d8fa3e142af9cfc20bb0b53dfa7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ac50861f97749eeb3a13c7eaa44d63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bade884f4544c9db1e91c2bafc2a6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_504e1f617ed14dfcad816d425c95044a",
            "placeholder": "​",
            "style": "IPY_MODEL_838274c16d974c47a6ded0635dd273b8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6bafca1fa3f54475a0ee55a09e2c2a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "700e52b083da4fe5b2527957ae0ffe45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70165e2d36eb41528777744d620ee131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3822e0b21d1948f4bfe3c505f82677b9",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b59d05df62ee4d66a91bb75cb1beb79f",
            "value": 493443
          }
        },
        "72407fd5546847b98a7d605fbefe9db5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b30d5d6eec40f396c7cc47f63b99bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a3ab22097134b01b253e19edd77b51d",
            "placeholder": "​",
            "style": "IPY_MODEL_e40e368e14584c3e97585190cc9d0cb8",
            "value": "generation_config.json: 100%"
          }
        },
        "7447ed86bd844b75b593e4a407d926a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74664f5070bc4143bc41d0b15ba5d2e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "746efe9dfbbc4e198685b87ca6554ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "751a6719f84847598942b32b052d592d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77c5d4048969465ba0f078aeaf1002e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ae6ac4fcfc5408aa42ce9faed94a1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f6d86aaaf474687ae6ebe96c57f7e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ec9ff2929ee47fb9ec1ac3aec6effed",
              "IPY_MODEL_5479cd9f848e40e59bf3aebffc548e86",
              "IPY_MODEL_2edd27009fd64446bad5efb9ce2394d5"
            ],
            "layout": "IPY_MODEL_41964f83005445eab064da2788ab8948"
          }
        },
        "82df653994bd48e28ad8d508c752fcf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1b2975b587d47319ac190e0e885513a",
            "placeholder": "​",
            "style": "IPY_MODEL_d4d31c0fb36f4760b5d8720b7fbde5dd",
            "value": " 3/3 [00:08&lt;00:00,  2.65s/it]"
          }
        },
        "838274c16d974c47a6ded0635dd273b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86aa45b9630e4fd0b27be2566387e5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_079f753989054a85ad03aba375a15441",
            "placeholder": "​",
            "style": "IPY_MODEL_f0af24af1e594499a7b31b43b5f00558",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 7.45MB/s]"
          }
        },
        "8841c914e02f4425af085379179d5015": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b410276c8e5143309db3c6ad545a912c",
            "placeholder": "​",
            "style": "IPY_MODEL_1f4023cd87d14cbd92e97283616fb472",
            "value": " 437/437 [00:00&lt;00:00, 35.1kB/s]"
          }
        },
        "886eedbb79784b7ea5419bcc48611859": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a72267cb84294293854572a9ea9ad837",
            "placeholder": "​",
            "style": "IPY_MODEL_eb8013c172384b0eaa4f4f542d6d60e9",
            "value": " 13.6M/13.6M [00:00&lt;00:00, 316MB/s]"
          }
        },
        "88ae7eee3e044e4ea2ec9143ae723579": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89dc24b55d0443a9b8e04967f4df6f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d2939a5c15542ccba9bf90c8ce8a6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ded652f6b194d6db9c223671edda9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f55ee660b6e47288225bab274ddb856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67084d8fa3e142af9cfc20bb0b53dfa7",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_518fe28eaf14419082ca5cd16ec3c7c9",
            "value": 3
          }
        },
        "907b4e4a8160453aba9f6fb53e15ba26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e651083693cd4f58a972fc3caa55049d",
              "IPY_MODEL_9522c96d797b4daa886770f64a766eec",
              "IPY_MODEL_6497b669aba14eb7b16e0ddabc193dbc"
            ],
            "layout": "IPY_MODEL_bd8f0b8734b84c4286588b1b2235a2f7"
          }
        },
        "909c654f2bfe4da7b26f52e720130a48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f6ce8e67964ec0b99c5b075e49cfd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df07d321191649b49472205cebea4aa0",
            "placeholder": "​",
            "style": "IPY_MODEL_f28fc516581548e3b148bcb4add265cd",
            "value": "adapter_config.json: 100%"
          }
        },
        "92b131f472f9477d8839c354bb03cc78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47d4c5607c75407db7572411d1536418",
            "placeholder": "​",
            "style": "IPY_MODEL_104ef6e8c2cf4ce698a061847b2593d4",
            "value": "tokenizer.model: 100%"
          }
        },
        "93fda078803d446494a3d38d47ce86f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "948cec41b5ce4455835d9208359d8b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9522c96d797b4daa886770f64a766eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b05b4cad090b473d818a9bfd4cb0671a",
            "max": 4158662096,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a904d4f76efe4182ab32bee42f6d828d",
            "value": 4158662096
          }
        },
        "96a6151b07ef470e9be1e5dfd45f8566": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "983258e7f35e4167bbf204c9cfbef6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9967d0294d27427e983411296c4a6b42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a7bb724379e4fe8b1de60ef79ce160a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9efd3dcf36624df0b674a2521a70daed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0101556661f42b5a391ec6a4684af6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0d30a714a214ecbae30ae97dc57f1df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1b2c9577b4a48e395cfe41ec09610dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf44965e965849d8bbbf8cc962038478",
              "IPY_MODEL_328bb007f2ca45b9aab116dfecfa4aa6",
              "IPY_MODEL_03acf0e3c5de4e498ccfdb6b24e22b64"
            ],
            "layout": "IPY_MODEL_74664f5070bc4143bc41d0b15ba5d2e8"
          }
        },
        "a30f6291eec84eb6b66e2d7a201fefd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a340be79b62347b38bf6ce12586b96f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a352253498d944019ee674691927537b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a491ebb17db84c13b2f5c0ba85f48fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5a8cafd713b4f4c9b8e7f15db3e9cb6",
            "max": 1795331,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fab6fb9e0e4c4253a16585f35e67e5c7",
            "value": 1795331
          }
        },
        "a562b110dabc458286f1cdd0ec05c9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bade884f4544c9db1e91c2bafc2a6ae",
              "IPY_MODEL_2752561a16c6413c9be9fb41ec7b4669",
              "IPY_MODEL_db4ea4f2dc8843429118177f383a166c"
            ],
            "layout": "IPY_MODEL_4a003abec19447b3b183a4d1d1908825"
          }
        },
        "a5ed04b16b2f45a29ea83dbff3d8ad6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6bfa24be9d0435f82603343ab530bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6c9cd78319f48f183058decb7f0d8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a71f067cdb2e40cba3a29b1b30617e71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a72267cb84294293854572a9ea9ad837": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a72b372c850641d9aad30ce8a784b81a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7788d690c9d45698f1f40a78716ca0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a904d4f76efe4182ab32bee42f6d828d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac5bc036e2504f5b9ca48539fefc99e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af77a15ad34f4b1b823aebad570dc404": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afd7ee119fb445d286625f49ea8ae268": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b05b4cad090b473d818a9bfd4cb0671a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11e1b59c0eb43a5bb63b0aad4aa5fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_433205a50bf349bab53f939d3f465c7b",
              "IPY_MODEL_a491ebb17db84c13b2f5c0ba85f48fba",
              "IPY_MODEL_86aa45b9630e4fd0b27be2566387e5a9"
            ],
            "layout": "IPY_MODEL_4a08ff8bf52c485d92a0176c35401260"
          }
        },
        "b2f3974cdc69446fae8deff40af448fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7447ed86bd844b75b593e4a407d926a7",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88ae7eee3e044e4ea2ec9143ae723579",
            "value": 493443
          }
        },
        "b410276c8e5143309db3c6ad545a912c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59d05df62ee4d66a91bb75cb1beb79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b91592c793664b01b5d56bf250da2bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba0253ece6bd4b3aa7bf2b6757091134": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcaea40435e5405b878c32d8bf703958": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5103eebc511d488db991271aba37c824",
            "placeholder": "​",
            "style": "IPY_MODEL_a5ed04b16b2f45a29ea83dbff3d8ad6e",
            "value": "tokenizer.model: 100%"
          }
        },
        "bd30d213272e4d96acecb40388286a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd6dc9e4488348058069956aa6e7bf72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8f0b8734b84c4286588b1b2235a2f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf98a7ade2584433806c0879416807a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c09d8bd43cbe481cae460719a75f341e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a8cafd713b4f4c9b8e7f15db3e9cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72e844242bc44e6a9a4bc403164b3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8448a26edbc462483e23758d6f3ac91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce096d140c13473788d6d5c4ab7dfb63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf44965e965849d8bbbf8cc962038478": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5489d57115254e6db8f781f26252e0ba",
            "placeholder": "​",
            "style": "IPY_MODEL_dd72152367b04806a82231e9febae878",
            "value": "added_tokens.json: 100%"
          }
        },
        "d4d31c0fb36f4760b5d8720b7fbde5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d68963bbe9ec4586ab7fed453b001290": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d960a1ea14674c90b95c39b2b55c1aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9efd3dcf36624df0b674a2521a70daed",
            "max": 652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e86481e42f8948399df8c37de3754a67",
            "value": 652
          }
        },
        "d9b8713c4a0b447ab48436986e5833d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da24161c184c4a79889eada154f6240b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db4ea4f2dc8843429118177f383a166c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_700e52b083da4fe5b2527957ae0ffe45",
            "placeholder": "​",
            "style": "IPY_MODEL_bd30d213272e4d96acecb40388286a46",
            "value": " 1.46k/1.46k [00:00&lt;00:00, 123kB/s]"
          }
        },
        "db7230f0d64c4b5b8771abdc46919da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f1b83380464363afb134331ce4cc55",
            "placeholder": "​",
            "style": "IPY_MODEL_5394e21a6d6e41af84e9d1aec7dff201",
            "value": " 652/652 [00:00&lt;00:00, 51.0kB/s]"
          }
        },
        "dbb0088887664a5d84cc17a78bce2237": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd72152367b04806a82231e9febae878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de552982a7814718a61614edf323b8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de920037a30f45568b1bdee400752ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16affd2ba0754498967f376cb693cade",
            "placeholder": "​",
            "style": "IPY_MODEL_006fe2a82244405ab22436287120edcc",
            "value": " 493k/493k [00:00&lt;00:00, 5.47MB/s]"
          }
        },
        "df07d321191649b49472205cebea4aa0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df95676707254ec8b765db7dea9293a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e15cf352a725415f83bf4a81d4b2091d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e196ce15d6c94736a9856699e431b944": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3739cfbe01e49a99fa5c91ae3b85c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da24161c184c4a79889eada154f6240b",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77c5d4048969465ba0f078aeaf1002e4",
            "value": 72
          }
        },
        "e38890a57fb14b118475733f9390903d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1286a53735574ca5b22451856e9ce66d",
              "IPY_MODEL_364ae175855c4992813a30cc9864b810",
              "IPY_MODEL_11a046ac18614a86894f31469592debb"
            ],
            "layout": "IPY_MODEL_9967d0294d27427e983411296c4a6b42"
          }
        },
        "e3e4ea448b70487d95c7157e50dbfd83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e40e368e14584c3e97585190cc9d0cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5a0f69f43b841d993383e2026017e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e651083693cd4f58a972fc3caa55049d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de552982a7814718a61614edf323b8cb",
            "placeholder": "​",
            "style": "IPY_MODEL_751a6719f84847598942b32b052d592d",
            "value": "model.safetensors: 100%"
          }
        },
        "e831330e459d42a39a5f6f70d4d0f060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e86481e42f8948399df8c37de3754a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e88426f2e34344c983bac1e1af5be2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb8013c172384b0eaa4f4f542d6d60e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef2f607cbfdb40a9b87745ac2d9046c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd3813f39a74346ab411f73b678a057": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dc6842683d04de9b67e5db139eecba3",
            "placeholder": "​",
            "style": "IPY_MODEL_948cec41b5ce4455835d9208359d8b52",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f0af24af1e594499a7b31b43b5f00558": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1b2975b587d47319ac190e0e885513a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28fc516581548e3b148bcb4add265cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3c51625c9a641f7a66c0b146acdd441": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9b8713c4a0b447ab48436986e5833d9",
            "placeholder": "​",
            "style": "IPY_MODEL_89dc24b55d0443a9b8e04967f4df6f15",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f3cdbc823928401f9673c8f7b6742fab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f492126461f04498b0c5e8640b2dcabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce096d140c13473788d6d5c4ab7dfb63",
            "placeholder": "​",
            "style": "IPY_MODEL_e88426f2e34344c983bac1e1af5be2f4",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 25.9MB/s]"
          }
        },
        "f9a150b9074c45629a730b5834925089": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fab6fb9e0e4c4253a16585f35e67e5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fad53ea590bb49d8808d1c33e1f68f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf0e262de994137bee8d455bdbdbc11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fde02c422e3c45498d2a03ede78f68ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22a2774bfb4e4667acc353fbba392d10",
            "placeholder": "​",
            "style": "IPY_MODEL_af77a15ad34f4b1b823aebad570dc404",
            "value": " 72.0/72.0 [00:00&lt;00:00, 5.44kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
